
% Default to the notebook output style

    


% Inherit from the specified cell style.




    
\documentclass[11pt]{article}

    
    
    \usepackage[T1]{fontenc}
    % Nicer default font (+ math font) than Computer Modern for most use cases
    \usepackage{mathpazo}

    % Basic figure setup, for now with no caption control since it's done
    % automatically by Pandoc (which extracts ![](path) syntax from Markdown).
    \usepackage{graphicx}
    % We will generate all images so they have a width \maxwidth. This means
    % that they will get their normal width if they fit onto the page, but
    % are scaled down if they would overflow the margins.
    \makeatletter
    \def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth
    \else\Gin@nat@width\fi}
    \makeatother
    \let\Oldincludegraphics\includegraphics
    % Set max figure width to be 80% of text width, for now hardcoded.
    \renewcommand{\includegraphics}[1]{\Oldincludegraphics[width=.8\maxwidth]{#1}}
    % Ensure that by default, figures have no caption (until we provide a
    % proper Figure object with a Caption API and a way to capture that
    % in the conversion process - todo).
    \usepackage{caption}
    \DeclareCaptionLabelFormat{nolabel}{}
    \captionsetup{labelformat=nolabel}

    \usepackage{adjustbox} % Used to constrain images to a maximum size 
    \usepackage{xcolor} % Allow colors to be defined
    \usepackage{enumerate} % Needed for markdown enumerations to work
    \usepackage{geometry} % Used to adjust the document margins
    \usepackage{amsmath} % Equations
    \usepackage{amssymb} % Equations
    \usepackage{textcomp} % defines textquotesingle
    % Hack from http://tex.stackexchange.com/a/47451/13684:
    \AtBeginDocument{%
        \def\PYZsq{\textquotesingle}% Upright quotes in Pygmentized code
    }
    \usepackage{upquote} % Upright quotes for verbatim code
    \usepackage{eurosym} % defines \euro
    \usepackage[mathletters]{ucs} % Extended unicode (utf-8) support
    \usepackage[utf8x]{inputenc} % Allow utf-8 characters in the tex document
    \usepackage{fancyvrb} % verbatim replacement that allows latex
    \usepackage{grffile} % extends the file name processing of package graphics 
                         % to support a larger range 
    % The hyperref package gives us a pdf with properly built
    % internal navigation ('pdf bookmarks' for the table of contents,
    % internal cross-reference links, web links for URLs, etc.)
    \usepackage{hyperref}
    \usepackage{longtable} % longtable support required by pandoc >1.10
    \usepackage{booktabs}  % table support for pandoc > 1.12.2
    \usepackage[inline]{enumitem} % IRkernel/repr support (it uses the enumerate* environment)
    \usepackage[normalem]{ulem} % ulem is needed to support strikethroughs (\sout)
                                % normalem makes italics be italics, not underlines
    

    
    
    % Colors for the hyperref package
    \definecolor{urlcolor}{rgb}{0,.145,.698}
    \definecolor{linkcolor}{rgb}{.71,0.21,0.01}
    \definecolor{citecolor}{rgb}{.12,.54,.11}

    % ANSI colors
    \definecolor{ansi-black}{HTML}{3E424D}
    \definecolor{ansi-black-intense}{HTML}{282C36}
    \definecolor{ansi-red}{HTML}{E75C58}
    \definecolor{ansi-red-intense}{HTML}{B22B31}
    \definecolor{ansi-green}{HTML}{00A250}
    \definecolor{ansi-green-intense}{HTML}{007427}
    \definecolor{ansi-yellow}{HTML}{DDB62B}
    \definecolor{ansi-yellow-intense}{HTML}{B27D12}
    \definecolor{ansi-blue}{HTML}{208FFB}
    \definecolor{ansi-blue-intense}{HTML}{0065CA}
    \definecolor{ansi-magenta}{HTML}{D160C4}
    \definecolor{ansi-magenta-intense}{HTML}{A03196}
    \definecolor{ansi-cyan}{HTML}{60C6C8}
    \definecolor{ansi-cyan-intense}{HTML}{258F8F}
    \definecolor{ansi-white}{HTML}{C5C1B4}
    \definecolor{ansi-white-intense}{HTML}{A1A6B2}

    % commands and environments needed by pandoc snippets
    % extracted from the output of `pandoc -s`
    \providecommand{\tightlist}{%
      \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
    \DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
    % Add ',fontsize=\small' for more characters per line
    \newenvironment{Shaded}{}{}
    \newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{{#1}}}}
    \newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.56,0.13,0.00}{{#1}}}
    \newcommand{\DecValTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\FloatTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\CharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\StringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\CommentTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textit{{#1}}}}
    \newcommand{\OtherTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{{#1}}}
    \newcommand{\AlertTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
    \newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.02,0.16,0.49}{{#1}}}
    \newcommand{\RegionMarkerTok}[1]{{#1}}
    \newcommand{\ErrorTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
    \newcommand{\NormalTok}[1]{{#1}}
    
    % Additional commands for more recent versions of Pandoc
    \newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.53,0.00,0.00}{{#1}}}
    \newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.73,0.40,0.53}{{#1}}}
    \newcommand{\ImportTok}[1]{{#1}}
    \newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.73,0.13,0.13}{\textit{{#1}}}}
    \newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\VariableTok}[1]{\textcolor[rgb]{0.10,0.09,0.49}{{#1}}}
    \newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{{#1}}}}
    \newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.40,0.40,0.40}{{#1}}}
    \newcommand{\BuiltInTok}[1]{{#1}}
    \newcommand{\ExtensionTok}[1]{{#1}}
    \newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.74,0.48,0.00}{{#1}}}
    \newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.49,0.56,0.16}{{#1}}}
    \newcommand{\InformationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\WarningTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    
    
    % Define a nice break command that doesn't care if a line doesn't already
    % exist.
    \def\br{\hspace*{\fill} \\* }
    % Math Jax compatability definitions
    \def\gt{>}
    \def\lt{<}
    % Document parameters
    \title{task01-initial-topic-investigation}
    
    
    

    % Pygments definitions
    
\makeatletter
\def\PY@reset{\let\PY@it=\relax \let\PY@bf=\relax%
    \let\PY@ul=\relax \let\PY@tc=\relax%
    \let\PY@bc=\relax \let\PY@ff=\relax}
\def\PY@tok#1{\csname PY@tok@#1\endcsname}
\def\PY@toks#1+{\ifx\relax#1\empty\else%
    \PY@tok{#1}\expandafter\PY@toks\fi}
\def\PY@do#1{\PY@bc{\PY@tc{\PY@ul{%
    \PY@it{\PY@bf{\PY@ff{#1}}}}}}}
\def\PY#1#2{\PY@reset\PY@toks#1+\relax+\PY@do{#2}}

\expandafter\def\csname PY@tok@w\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.73,0.73}{##1}}}
\expandafter\def\csname PY@tok@c\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.74,0.48,0.00}{##1}}}
\expandafter\def\csname PY@tok@k\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kt\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.69,0.00,0.25}{##1}}}
\expandafter\def\csname PY@tok@o\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@ow\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\expandafter\def\csname PY@tok@nb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@nf\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@nc\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@nn\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@ne\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.82,0.25,0.23}{##1}}}
\expandafter\def\csname PY@tok@nv\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@no\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.53,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@nl\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.63,0.63,0.00}{##1}}}
\expandafter\def\csname PY@tok@ni\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.60,0.60,0.60}{##1}}}
\expandafter\def\csname PY@tok@na\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.49,0.56,0.16}{##1}}}
\expandafter\def\csname PY@tok@nt\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@nd\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\expandafter\def\csname PY@tok@s\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sd\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@si\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.53}{##1}}}
\expandafter\def\csname PY@tok@se\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.13}{##1}}}
\expandafter\def\csname PY@tok@sr\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.53}{##1}}}
\expandafter\def\csname PY@tok@ss\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@sx\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@m\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@gh\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@gu\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.50,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@gd\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.63,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@gi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.63,0.00}{##1}}}
\expandafter\def\csname PY@tok@gr\endcsname{\def\PY@tc##1{\textcolor[rgb]{1.00,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@ge\endcsname{\let\PY@it=\textit}
\expandafter\def\csname PY@tok@gs\endcsname{\let\PY@bf=\textbf}
\expandafter\def\csname PY@tok@gp\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@go\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.53,0.53,0.53}{##1}}}
\expandafter\def\csname PY@tok@gt\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.27,0.87}{##1}}}
\expandafter\def\csname PY@tok@err\endcsname{\def\PY@bc##1{\setlength{\fboxsep}{0pt}\fcolorbox[rgb]{1.00,0.00,0.00}{1,1,1}{\strut ##1}}}
\expandafter\def\csname PY@tok@kc\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kd\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kn\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kr\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@bp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@fm\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@vc\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@vg\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@vi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@vm\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@sa\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sc\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@dl\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@s2\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sh\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@s1\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@mb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mf\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mh\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@il\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mo\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@ch\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cm\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cpf\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@c1\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cs\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}

\def\PYZbs{\char`\\}
\def\PYZus{\char`\_}
\def\PYZob{\char`\{}
\def\PYZcb{\char`\}}
\def\PYZca{\char`\^}
\def\PYZam{\char`\&}
\def\PYZlt{\char`\<}
\def\PYZgt{\char`\>}
\def\PYZsh{\char`\#}
\def\PYZpc{\char`\%}
\def\PYZdl{\char`\$}
\def\PYZhy{\char`\-}
\def\PYZsq{\char`\'}
\def\PYZdq{\char`\"}
\def\PYZti{\char`\~}
% for compatibility with earlier versions
\def\PYZat{@}
\def\PYZlb{[}
\def\PYZrb{]}
\makeatother


    % Exact colors from NB
    \definecolor{incolor}{rgb}{0.0, 0.0, 0.5}
    \definecolor{outcolor}{rgb}{0.545, 0.0, 0.0}



    
    % Prevent overflowing lines due to hard-to-break entities
    \sloppy 
    % Setup hyperref package
    \hypersetup{
      breaklinks=true,  % so long urls are correctly broken across lines
      colorlinks=true,
      urlcolor=urlcolor,
      linkcolor=linkcolor,
      citecolor=citecolor,
      }
    % Slightly bigger margins than the latex defaults
    
    \geometry{verbose,tmargin=1in,bmargin=1in,lmargin=1in,rmargin=1in}
    
    

    \begin{document}
    
    
    \maketitle
    
    

    
    \hypertarget{univ.-of-illinois-data-mining-project-on-coursera}{%
\section{Univ. of Illinois Data Mining Project on
Coursera}\label{univ.-of-illinois-data-mining-project-on-coursera}}

\hypertarget{task-01---initial-topic-investigation}{%
\subsection{Task 01 - Initial Topic
Investigation}\label{task-01---initial-topic-investigation}}

2018-09-16 loganjtravis@gmail.com (Logan Travis)

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}4}]:} \PY{c+c1}{\PYZsh{} Suppress warnings. Python 3.7 complains about a number of packages using a soon to be deprecated}
        \PY{c+c1}{\PYZsh{} import syntax.}
        \PY{k+kn}{import} \PY{n+nn}{warnings}
        \PY{n}{warnings}\PY{o}{.}\PY{n}{filterwarnings}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{ignore}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}5}]:} \PY{c+c1}{\PYZsh{} Imports}
        \PY{k+kn}{import} \PY{n+nn}{os}\PY{o}{,} \PY{n+nn}{pickle}\PY{o}{,} \PY{n+nn}{random}
        \PY{k+kn}{import} \PY{n+nn}{gensim}\PY{n+nn}{.}\PY{n+nn}{models} \PY{k}{as} \PY{n+nn}{models}\PY{o}{,} \PY{n+nn}{gensim}\PY{n+nn}{.}\PY{n+nn}{matutils} \PY{k}{as} \PY{n+nn}{matutils}\PY{o}{,} \PY{n+nn}{gensim}\PY{n+nn}{.}\PY{n+nn}{corpora} \PY{k}{as} \PY{n+nn}{corpora}
        \PY{k+kn}{import} \PY{n+nn}{nltk}
        \PY{k+kn}{from} \PY{n+nn}{scipy}\PY{n+nn}{.}\PY{n+nn}{sparse} \PY{k}{import} \PY{n}{load\PYZus{}npz}\PY{p}{,} \PY{n}{save\PYZus{}npz}
        \PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{feature\PYZus{}extraction}\PY{n+nn}{.}\PY{n+nn}{text} \PY{k}{import} \PY{n}{TfidfVectorizer}
        \PY{k+kn}{import} \PY{n+nn}{pandas} \PY{k}{as} \PY{n+nn}{pd}
        \PY{k+kn}{import} \PY{n+nn}{pyLDAvis}\PY{n+nn}{.}\PY{n+nn}{gensim}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}6}]:} \PY{c+c1}{\PYZsh{} Set random seed for repeatability}
        \PY{n}{random}\PY{o}{.}\PY{n}{seed}\PY{p}{(}\PY{l+m+mi}{42}\PY{p}{)}
\end{Verbatim}


    \hypertarget{summary}{%
\subsubsection{Summary}\label{summary}}

From course page
\href{https://www.coursera.org/learn/data-mining-project/supplement/z2jpZ/task-1-overview}{Week
1 \textgreater{} Task 1 Information \textgreater{} Task 1 Overview}:

\begin{quote}
The goal of this task is to explore the Yelp data set to get a sense
about what the data look like and their characteristics. You can think
about the goal as being to answer questions such as:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  What are the major topics in the reviews? Are they different in the
  positive and negative reviews? Are they different for different
  cuisines?
\item
  What does the distribution of the number of reviews over other
  variables (e.g., cuisine, location) look like?
\item
  What does the distribution of ratings look like?
\end{enumerate}

In general, you can address such questions by showing visualization of
statistics computed based on the data set or topics extracted from
review text.
\end{quote}

    \hypertarget{grading-rubric}{%
\subsubsection{Grading Rubric}\label{grading-rubric}}

From course page
\href{https://www.coursera.org/learn/data-mining-project/supplement/Xk8lq/task-1-rubric}{Week
1 \textgreater{} Task 1 Information \textgreater{} Task 1 Rubric}:

\begin{quote}
You will evaluate your peers' submission for Task 1 using this rubric.
While evaluating, consider the following questions:

\begin{itemize}
\tightlist
\item
  Application of a topic model: Was the description of the topic
  modeling procedure clear enough such that you can produce the same
  results?
\item
  Topic visualization: Does the topic visualization effectively display
  the data?
\item
  Data exploration: Was the description of the two sets of data they
  selected for comparison clear enough to follow?
\item
  Visualization comparison: Does the visualization component highlight
  the differences/similarities between the data?
\end{itemize}

Note that the examples listed in the ``Excellent'' column are not an
exclusive list for each category. You may choose to award 6 points for
any effort in your peers' submissions that goes beyond what is required.

\begin{longtable}[]{@{}lllll@{}}
\toprule
\begin{minipage}[b]{0.17\columnwidth}\raggedright
Criteria\strut
\end{minipage} & \begin{minipage}[b]{0.17\columnwidth}\raggedright
Poor (1 point)\strut
\end{minipage} & \begin{minipage}[b]{0.17\columnwidth}\raggedright
Fair (3 points)\strut
\end{minipage} & \begin{minipage}[b]{0.17\columnwidth}\raggedright
Good (5 points)\strut
\end{minipage} & \begin{minipage}[b]{0.17\columnwidth}\raggedright
Excellent (6 points)\strut
\end{minipage}\tabularnewline
\midrule
\endhead
\begin{minipage}[t]{0.17\columnwidth}\raggedright
\textbf{Task 1.1: Application of a topic model}\strut
\end{minipage} & \begin{minipage}[t]{0.17\columnwidth}\raggedright
A topic model was either not used or did not generate any topic.\strut
\end{minipage} & \begin{minipage}[t]{0.17\columnwidth}\raggedright
A topic model was used, but the report fails to mention what model was
used and/or how it is applied to the data set.\strut
\end{minipage} & \begin{minipage}[t]{0.17\columnwidth}\raggedright
The report clearly explains what topic model was used and how it was
applied to the data set.\strut
\end{minipage} & \begin{minipage}[t]{0.17\columnwidth}\raggedright
For example, multiple topic models were used and the report analyzes the
differences between them.\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.17\columnwidth}\raggedright
\textbf{Task 1.1: Generated visualization}\strut
\end{minipage} & \begin{minipage}[t]{0.17\columnwidth}\raggedright
The visualization is either absent or useless.\strut
\end{minipage} & \begin{minipage}[t]{0.17\columnwidth}\raggedright
The visualization is present but does not help make clear what topics
the people have talked about in the reviews.\strut
\end{minipage} & \begin{minipage}[t]{0.17\columnwidth}\raggedright
The visualization clearly shows and distinguishes what topics people
have talked about in the reviews.\strut
\end{minipage} & \begin{minipage}[t]{0.17\columnwidth}\raggedright
For example, multiple visualizations were used and the report analyzes
the comparative strengths of each.\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.17\columnwidth}\raggedright
\textbf{Task 1.2: Generated sets of topics}\strut
\end{minipage} & \begin{minipage}[t]{0.17\columnwidth}\raggedright
The two subsets are not comparable.\strut
\end{minipage} & \begin{minipage}[t]{0.17\columnwidth}\raggedright
The two subsets are comparable. A topic model was used on the two
subsets, but the report fails to mention what model was used and/or how
it was applied to the data set.\strut
\end{minipage} & \begin{minipage}[t]{0.17\columnwidth}\raggedright
The two subsets are comparable. The report clearly explains what topic
model was used and how it was applied to the two subsets.\strut
\end{minipage} & \begin{minipage}[t]{0.17\columnwidth}\raggedright
For example, multiple interesting subsets were identified and assessed
for their usefulness, or multiple topic models were applied to the two
subsets with differences between them analyzed.\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.17\columnwidth}\raggedright
\textbf{Task 1.2: Visualization of comparison}\strut
\end{minipage} & \begin{minipage}[t]{0.17\columnwidth}\raggedright
The two subsets are visualized in such a way that similarities and
differences are not clear.\strut
\end{minipage} & \begin{minipage}[t]{0.17\columnwidth}\raggedright
The two subsets are visualized in such a way to show the similarity of
the two subsets, but no attempt was made to show the differences.\strut
\end{minipage} & \begin{minipage}[t]{0.17\columnwidth}\raggedright
The two subsets are visualized in such a way that both similarities and
differences are very apparent.\strut
\end{minipage} & \begin{minipage}[t]{0.17\columnwidth}\raggedright
Extra transformation of the data was done to improve visualization, or
multiple ways of visualizing the topics were used to provide a very
comprehensive comparison.\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.17\columnwidth}\raggedright
\textbf{Visualizations: Appropriateness of choice}\strut
\end{minipage} & \begin{minipage}[t]{0.17\columnwidth}\raggedright
The visualization methods are not suitable for the type of data.\strut
\end{minipage} & \begin{minipage}[t]{0.17\columnwidth}\raggedright
The visualization methods are suitable for the type of data, but another
way to visualize the data is clearly better.\strut
\end{minipage} & \begin{minipage}[t]{0.17\columnwidth}\raggedright
The visualization methods used are quite suitable for the type of data
and made relationships clear.\strut
\end{minipage} & \begin{minipage}[t]{0.17\columnwidth}\raggedright
Furthermore, extra effort was made to make the visualizations
beautifully designed and/or usefully interactive.\strut
\end{minipage}\tabularnewline
\bottomrule
\end{longtable}
\end{quote}

    \hypertarget{get-data-set}{%
\subsubsection{Get Data Set}\label{get-data-set}}

Note: I cleaned and saved a Pandas dataframe (as a GZIPped pickle) from
the Yelp reviews dataset in a separate notebook
``task00-yelp-reviews-to-pandas-dataframe.ipynb''.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}7}]:} \PY{c+c1}{\PYZsh{} Set paths to data source, work in process (\PYZdq{}WIP\PYZdq{}), and output}
        \PY{n}{PATH\PYZus{}SOURCE} \PY{o}{=} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{source/}\PY{l+s+s2}{\PYZdq{}}
        \PY{n}{PATH\PYZus{}WIP} \PY{o}{=} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{wip/}\PY{l+s+s2}{\PYZdq{}}
        \PY{n}{PATH\PYZus{}OUTPUT} \PY{o}{=} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{output/}\PY{l+s+s2}{\PYZdq{}}
        
        \PY{c+c1}{\PYZsh{} Set review file path}
        \PY{n}{PATH\PYZus{}SOURCE\PYZus{}YELP\PYZus{}REVIEWS} \PY{o}{=} \PY{n}{PATH\PYZus{}SOURCE} \PY{o}{+} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{yelp\PYZus{}academic\PYZus{}dataset\PYZus{}review.pkl.gzip}\PY{l+s+s2}{\PYZdq{}}
        \PY{n}{PATH\PYZus{}WIP\PYZus{}TOKENIZER} \PY{o}{=} \PY{n}{PATH\PYZus{}WIP} \PY{o}{+} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{task01\PYZus{}tokenizer.pkl}\PY{l+s+s2}{\PYZdq{}}
        \PY{n}{PATH\PYZus{}WIP\PYZus{}TOKEN\PYZus{}MATRIX} \PY{o}{=} \PY{n}{PATH\PYZus{}WIP} \PY{o}{+} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{task01\PYZus{}token\PYZus{}matrix.npz}\PY{l+s+s2}{\PYZdq{}}
        \PY{n}{PATH\PYZus{}WIP\PYZus{}LDA\PYZus{}MODEL} \PY{o}{=} \PY{n}{PATH\PYZus{}WIP} \PY{o}{+} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{taks01\PYZus{}lda\PYZus{}model}\PY{l+s+s2}{\PYZdq{}}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}8}]:} \PY{c+c1}{\PYZsh{} Read pickled dataframe}
        \PY{n}{dfYelpReviews} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{read\PYZus{}pickle}\PY{p}{(}\PY{n}{PATH\PYZus{}SOURCE\PYZus{}YELP\PYZus{}REVIEWS}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}9}]:} \PY{c+c1}{\PYZsh{} Print dataframe shape and head}
        \PY{n+nb}{print}\PY{p}{(}\PY{n}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Shape: }\PY{l+s+si}{\PYZob{}dfYelpReviews.shape\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
        \PY{n}{dfYelpReviews}\PY{o}{.}\PY{n}{head}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
Shape: (1125458, 9)

    \end{Verbatim}

\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}9}]:}                                    business\_id       date  stars  \textbackslash{}
        review\_id                                                          
        15SdjuK7DmYqUAj6rjGowg  vcNAWiLM4dR7D2nwwJ7nCA 2007-05-17      5   
        RF6UnRTtG7tWMcrO2GEoAg  vcNAWiLM4dR7D2nwwJ7nCA 2010-03-22      2   
        -TsVN230RCkLYKBeLsuz7A  vcNAWiLM4dR7D2nwwJ7nCA 2012-02-14      4   
        dNocEAyUucjT371NNND41Q  vcNAWiLM4dR7D2nwwJ7nCA 2012-03-02      4   
        ebcN2aqmNUuYNoyvQErgnA  vcNAWiLM4dR7D2nwwJ7nCA 2012-05-15      4   
        
                                                                             text  \textbackslash{}
        review\_id                                                                   
        15SdjuK7DmYqUAj6rjGowg  dr. goldberg offers everything i look for in a{\ldots}   
        RF6UnRTtG7tWMcrO2GEoAg  Unfortunately, the frustration of being Dr. Go{\ldots}   
        -TsVN230RCkLYKBeLsuz7A  Dr. Goldberg has been my doctor for years and {\ldots}   
        dNocEAyUucjT371NNND41Q  Been going to Dr. Goldberg for over 10 years. {\ldots}   
        ebcN2aqmNUuYNoyvQErgnA  Got a letter in the mail last week that said D{\ldots}   
        
                                  type                 user\_id  votes\_cool  \textbackslash{}
        review\_id                                                            
        15SdjuK7DmYqUAj6rjGowg  review  Xqd0DzHaiyRqVH3WRG7hzg           1   
        RF6UnRTtG7tWMcrO2GEoAg  review  H1kH6QZV7Le4zqTRNxoZow           0   
        -TsVN230RCkLYKBeLsuz7A  review  zvJCcrpm2yOZrxKffwGQLA           1   
        dNocEAyUucjT371NNND41Q  review  KBLW4wJA\_fwoWmMhiHRVOA           0   
        ebcN2aqmNUuYNoyvQErgnA  review  zvJCcrpm2yOZrxKffwGQLA           1   
        
                                votes\_funny  votes\_useful  
        review\_id                                          
        15SdjuK7DmYqUAj6rjGowg            0             2  
        RF6UnRTtG7tWMcrO2GEoAg            0             2  
        -TsVN230RCkLYKBeLsuz7A            0             1  
        dNocEAyUucjT371NNND41Q            0             0  
        ebcN2aqmNUuYNoyvQErgnA            0             2  
\end{Verbatim}
            
    \hypertarget{tf-idf}{%
\subsubsection{TF-IDF}\label{tf-idf}}

\begin{itemize}
\item
\end{itemize}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}10}]:} \PY{c+c1}{\PYZsh{} Set flag to load token matrix from file if found; set this to False when changing}
         \PY{c+c1}{\PYZsh{} other parameters}
         \PY{n}{load\PYZus{}token\PYZus{}matrix\PYZus{}from\PYZus{}file} \PY{o}{=} \PY{k+kc}{True}
         \PY{n}{overwrite\PYZus{}saved\PYZus{}token\PYZus{}matrix} \PY{o}{=} \PY{o+ow}{not} \PY{n}{load\PYZus{}token\PYZus{}matrix\PYZus{}from\PYZus{}file}
         
         \PY{c+c1}{\PYZsh{} Set token limit}
         \PY{n}{max\PYZus{}features} \PY{o}{=} \PY{l+m+mi}{10000}
         
         \PY{c+c1}{\PYZsh{} Set document frequency ceiling; topic analysis will ignore words found in more documents}
         \PY{n}{max\PYZus{}df} \PY{o}{=} \PY{l+m+mf}{0.5}
         
         \PY{c+c1}{\PYZsh{} Set document frequency floor; topic analysis will ignore words found in fewer document}
         \PY{n}{min\PYZus{}df} \PY{o}{=} \PY{l+m+mf}{0.001}
\end{Verbatim}


    \hypertarget{custom-tokenizer}{%
\paragraph{Custom Tokenizer}\label{custom-tokenizer}}

The \texttt{TfidVectorizer} class has a default pre-processor and
tokenizer. While the pre-processing steps meet my needs (i.e.,
puncuation removal and setting lower-case) the tokenizer does not
lemmatize nor stem words. Those two additional steps should produce more
stable topics. I therefore create my own tokenizer.

Note: I create \texttt{MyTokenizer} is a class to internalize
instantiation of NLK's \texttt{WordNetLemmatizer}.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}11}]:} \PY{k}{class} \PY{n+nc}{MyTokenizer}\PY{p}{:}
             \PY{k}{def} \PY{n+nf}{\PYZus{}\PYZus{}init\PYZus{}\PYZus{}}\PY{p}{(}\PY{n+nb+bp}{self}\PY{p}{)}\PY{p}{:}
                 \PY{l+s+sd}{\PYZdq{}\PYZdq{}\PYZdq{}String tokenizer utilizing lemmatizing and stemming.\PYZdq{}\PYZdq{}\PYZdq{}}
                 \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{wnl} \PY{o}{=} \PY{n}{nltk}\PY{o}{.}\PY{n}{stem}\PY{o}{.}\PY{n}{WordNetLemmatizer}\PY{p}{(}\PY{p}{)}
             
             \PY{k}{def} \PY{n+nf}{\PYZus{}\PYZus{}call\PYZus{}\PYZus{}}\PY{p}{(}\PY{n+nb+bp}{self}\PY{p}{,} \PY{n}{document}\PY{p}{)}\PY{p}{:}
                 \PY{l+s+sd}{\PYZdq{}\PYZdq{}\PYZdq{}Return tokens from a string.\PYZdq{}\PYZdq{}\PYZdq{}}
                 \PY{k}{return} \PY{p}{[}\PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{wnl}\PY{o}{.}\PY{n}{lemmatize}\PY{p}{(}\PY{n}{token}\PY{p}{)} \PY{k}{for} \PY{n}{token} \PY{o+ow}{in} \PY{n}{nltk}\PY{o}{.}\PY{n}{word\PYZus{}tokenize}\PY{p}{(}\PY{n}{document}\PY{p}{)}\PY{p}{]}
\end{Verbatim}


    \hypertarget{vectorized-tf-idf}{%
\paragraph{Vectorized TF-IDF}\label{vectorized-tf-idf}}

\begin{itemize}
\item
\end{itemize}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}12}]:} \PY{c+c1}{\PYZsh{} Create TF\PYZhy{}IDF vectorizer limiting }
         \PY{n}{vectorizer} \PY{o}{=} \PY{n}{TfidfVectorizer}\PY{p}{(}\PY{n}{max\PYZus{}features}\PY{o}{=}\PY{n}{max\PYZus{}features}\PY{p}{,} \PY{n}{max\PYZus{}df}\PY{o}{=}\PY{n}{max\PYZus{}df}\PY{p}{,} \PY{n}{min\PYZus{}df}\PY{o}{=}\PY{n}{min\PYZus{}df}\PY{p}{,} \PYZbs{}
                                     \PY{n}{stop\PYZus{}words}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{english}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{use\PYZus{}idf}\PY{o}{=}\PY{k+kc}{True}\PY{p}{,} \PY{n}{tokenizer}\PY{o}{=}\PY{n}{MyTokenizer}\PY{p}{(}\PY{p}{)}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}13}]:} \PY{c+c1}{\PYZsh{} Set working dataframe to a 30\PYZpc{} sample of the full data set; too large otherwise}
         \PY{n}{df} \PY{o}{=} \PY{n}{dfYelpReviews}\PY{o}{.}\PY{n}{sample}\PY{p}{(}\PY{n}{frac}\PY{o}{=}\PY{l+m+mf}{0.3}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}14}]:} \PY{o}{\PYZpc{}\PYZpc{}}\PY{k}{time}
         \PYZsh{} Load token matrix and vectorizer from file if found and flag set to permit;
         \PYZsh{} otherwise vectorize documents
         tokenMatrix = None
         if(load\PYZus{}token\PYZus{}matrix\PYZus{}from\PYZus{}file and \PYZbs{}
            os.path.isfile(PATH\PYZus{}WIP\PYZus{}TOKEN\PYZus{}MATRIX) and 
            os.path.isfile(PATH\PYZus{}WIP\PYZus{}TOKENIZER)):
             print(f\PYZdq{}Loading token matrix from file \PYZbs{}\PYZdq{}\PYZob{}PATH\PYZus{}WIP\PYZus{}TOKEN\PYZus{}MATRIX\PYZcb{}\PYZbs{}\PYZdq{}...\PYZdq{})
             tokenMatrix = load\PYZus{}npz(PATH\PYZus{}WIP\PYZus{}TOKEN\PYZus{}MATRIX)
             f = open(PATH\PYZus{}WIP\PYZus{}TOKENIZER, \PYZdq{}rb\PYZdq{})
             vectorizer = pickle.load(f)
             f.close()
         else:
             print(\PYZdq{}Vectorizing documents to build token matrix...\PYZdq{})
             tokenMatrix = vectorizer.fit\PYZus{}transform(df.text)
             overwrite\PYZus{}saved\PYZus{}token\PYZus{}matrix = True
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
Loading token matrix from file "wip/task01\_token\_matrix.npz"{\ldots}
CPU times: user 1.17 s, sys: 83.4 ms, total: 1.26 s
Wall time: 1.25 s

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}15}]:} \PY{c+c1}{\PYZsh{} Print token matrix shape}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Found }\PY{l+s+si}{\PYZob{}0[1]:,\PYZcb{}}\PY{l+s+s2}{ tokens in }\PY{l+s+si}{\PYZob{}0[0]:,\PYZcb{}}\PY{l+s+s2}{ documents}\PY{l+s+s2}{\PYZdq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{tokenMatrix}\PY{o}{.}\PY{n}{shape}\PY{p}{)}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
Found 4,653 tokens in 337,637 documents

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}16}]:} \PY{c+c1}{\PYZsh{} Save token matrix and vectorizer to file if changed}
         \PY{k}{if}\PY{p}{(}\PY{n}{overwrite\PYZus{}saved\PYZus{}token\PYZus{}matrix}\PY{p}{)}\PY{p}{:}
             \PY{n}{save\PYZus{}npz}\PY{p}{(}\PY{n}{PATH\PYZus{}WIP\PYZus{}TOKEN\PYZus{}MATRIX}\PY{p}{,} \PY{n}{tokenMatrix}\PY{p}{)}
             \PY{n}{f} \PY{o}{=} \PY{n+nb}{open}\PY{p}{(}\PY{n}{PATH\PYZus{}WIP\PYZus{}TOKENIZER}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{wb}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
             \PY{n}{pickle}\PY{o}{.}\PY{n}{dump}\PY{p}{(}\PY{n}{vectorizer}\PY{p}{,} \PY{n}{f}\PY{p}{)}
             \PY{n}{f}\PY{o}{.}\PY{n}{close}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


    \hypertarget{find-topics-using-lda}{%
\subsubsection{Find Topics Using LDA}\label{find-topics-using-lda}}

\begin{itemize}
\item
\end{itemize}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}47}]:} \PY{c+c1}{\PYZsh{} Set flag to load LDA model from file if found; set this to False when changing}
         \PY{c+c1}{\PYZsh{} other parameters}
         \PY{n}{load\PYZus{}lda\PYZus{}model\PYZus{}from\PYZus{}file} \PY{o}{=} \PY{k+kc}{True}
         \PY{n}{overwrite\PYZus{}saved\PYZus{}lda\PYZus{}model} \PY{o}{=} \PY{o+ow}{not} \PY{n}{load\PYZus{}lda\PYZus{}model\PYZus{}from\PYZus{}file}
         
         \PY{c+c1}{\PYZsh{} Set number of topics}
         \PY{n}{num\PYZus{}topics} \PY{o}{=} \PY{l+m+mi}{50}
         
         \PY{c+c1}{\PYZsh{} Set number of words to display for each topic}
         \PY{n}{num\PYZus{}words} \PY{o}{=} \PY{l+m+mi}{10}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}48}]:} \PY{c+c1}{\PYZsh{} Convert GenSim corpus from token vectors}
         \PY{n}{corpus} \PY{o}{=} \PY{n}{matutils}\PY{o}{.}\PY{n}{Sparse2Corpus}\PY{p}{(}\PY{n}{tokenMatrix}\PY{p}{,} \PY{n}{documents\PYZus{}columns}\PY{o}{=}\PY{k+kc}{False}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}49}]:} \PY{c+c1}{\PYZsh{} Create a GenSim dictionary for documents; Note: Passes the vectorizer tokens as}
         \PY{c+c1}{\PYZsh{} a single \PYZdq{}document\PYZdq{}.}
         \PY{n}{dictionary} \PY{o}{=} \PY{n}{corpora}\PY{o}{.}\PY{n}{Dictionary}\PY{p}{(}\PY{p}{[}\PY{n}{vectorizer}\PY{o}{.}\PY{n}{get\PYZus{}feature\PYZus{}names}\PY{p}{(}\PY{p}{)}\PY{p}{]}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}50}]:} \PY{o}{\PYZpc{}\PYZpc{}}\PY{k}{time}
         \PYZsh{} Load LDA model form file if found and flag set to permit; otherwise find topics
         lda = None
         if(load\PYZus{}lda\PYZus{}model\PYZus{}from\PYZus{}file and \PYZbs{}
            os.path.isfile(PATH\PYZus{}WIP\PYZus{}LDA\PYZus{}MODEL)):
             print(f\PYZdq{}Loading LDA model from \PYZbs{}\PYZdq{}\PYZob{}PATH\PYZus{}WIP\PYZus{}LDA\PYZus{}MODEL\PYZcb{}\PYZbs{}\PYZdq{}...\PYZdq{})
             lda = models.ldamulticore.LdaMulticore.load(PATH\PYZus{}WIP\PYZus{}LDA\PYZus{}MODEL)
         else:
             print(\PYZdq{}Finding topics using LDA...\PYZdq{})
             lda = models.ldamulticore.LdaMulticore(corpus, num\PYZus{}topics=num\PYZus{}topics, id2word=dict(dictionary.items()))
             overwrite\PYZus{}saved\PYZus{}lda\PYZus{}model = True
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
Finding topics using LDA{\ldots}
CPU times: user 4min 42s, sys: 4.25 s, total: 4min 46s
Wall time: 4min 45s

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}54}]:} \PY{c+c1}{\PYZsh{} Print topics}
         \PY{n}{lda}\PY{o}{.}\PY{n}{show\PYZus{}topics}\PY{p}{(}\PY{n}{num\PYZus{}topics}\PY{o}{=}\PY{n}{num\PYZus{}topics}\PY{p}{,} \PY{n}{num\PYZus{}words}\PY{o}{=}\PY{n}{num\PYZus{}words}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}54}]:} [(0,
           '0.028*"filipino" + 0.023*"candy" + 0.022*"bistro" + 0.022*"ravioli" + 0.019*"cheeseburger" + 0.019*"safeway" + 0.018*"di" + 0.018*"ramsay" + 0.017*"jose" + 0.016*"tony"'),
          (1,
           '0.028*"massage" + 0.015*"spa" + 0.013*"haircut" + 0.009*"great" + 0.009*"groupon" + 0.008*"facial" + 0.007*"barber" + 0.007*"workout" + 0.007*"hair" + 0.007*"relaxing"'),
          (2,
           '0.024*"dog" + 0.012*"dr." + 0.010*"doctor" + 0.009*"care" + 0.008*"pet" + 0.008*"office" + 0.008*"patient" + 0.007*"staff" + 0.007*"animal" + 0.006*"n\textbackslash{}'t"'),
          (3,
           '0.019*"gelato" + 0.015*"omelette" + 0.014*"cookie" + 0.013*"cooky" + 0.012*"]" + 0.012*"cheesecake" + 0.011*"juice" + 0.010*"http" + 0.010*"croissant" + 0.010*"john"'),
          (4,
           '0.035*"irish" + 0.027*"print" + 0.026*"beatles" + 0.026*"bank" + 0.025*"refund" + 0.024*"jungle" + 0.023*"hut" + 0.018*"voucher" + 0.016*"robert" + 0.016*"pickup"'),
          (5,
           '0.042*"great" + 0.030*"food" + 0.022*"korean" + 0.021*"awesome" + 0.020*"service" + 0.018*"atmosphere" + 0.015*"hawaiian" + 0.013*"place" + 0.011*"flower" + 0.009*"def"'),
          (6,
           '0.027*"1." + 0.026*"2." + 0.025*"3." + 0.021*"hawaii" + 0.020*"crawfish" + 0.020*"5." + 0.018*"4." + 0.017*"milkshake" + 0.016*"stone" + 0.015*"hooter"'),
          (7,
           '0.015*"breakfast" + 0.013*"egg" + 0.008*"hash" + 0.008*"pancake" + 0.008*"good" + 0.008*"potato" + 0.007*"crepe" + 0.007*"waffle" + 0.007*"gravy" + 0.007*"pie"'),
          (8,
           '0.028*"gas" + 0.025*"truck" + 0.025*"insurance" + 0.023*"pasty" + 0.012*"bug" + 0.011*"costume" + 0.011*"fav" + 0.011*"canal" + 0.011*"speedy" + 0.010*"ship"'),
          (9,
           '0.034*"sum" + 0.032*"wedding" + 0.030*"dim" + 0.023*"bouchon" + 0.021*"doughnut" + 0.019*"cart" + 0.018*"diego" + 0.017*"cent" + 0.017*"take-out" + 0.017*"everytime"'),
          (10,
           '0.011*"salad" + 0.010*"sandwich" + 0.008*"gyro" + 0.007*"pita" + 0.007*")" + 0.006*"good" + 0.006*"cheese" + 0.006*"\textbackslash{}'s" + 0.006*"(" + 0.006*"bread"'),
          (11,
           '0.014*"puppy" + 0.014*"practice" + 0.012*"tattoo" + 0.011*"artist" + 0.010*"unprofessional" + 0.010*"george" + 0.010*"max" + 0.009*"filthy" + 0.009*"frame" + 0.009*"genuinely"'),
          (12,
           '0.020*"taco" + 0.013*"mexican" + 0.011*"salsa" + 0.011*"food" + 0.009*"burrito" + 0.009*"good" + 0.008*"chip" + 0.008*"\textbackslash{}'s" + 0.007*"place" + 0.007*"bean"'),
          (13,
           '0.062*"movie" + 0.061*"theater" + 0.036*"philly" + 0.033*"seat" + 0.021*"theatre" + 0.020*"planet" + 0.020*"cheesesteak" + 0.019*"mon" + 0.018*"marinara" + 0.018*"hollywood"'),
          (14,
           '0.034*"room" + 0.027*"hotel" + 0.014*"stay" + 0.011*"casino" + 0.011*"pool" + 0.011*"strip" + 0.010*"stayed" + 0.009*"nice" + 0.009*"bed" + 0.008*"vega"'),
          (15,
           '0.015*"bike" + 0.015*"tour" + 0.011*"ride" + 0.011*"trail" + 0.011*"museum" + 0.011*"exhibit" + 0.007*"photo" + 0.007*"tank" + 0.007*"guide" + 0.007*"history"'),
          (16,
           '0.046*"burger" + 0.025*"fry" + 0.010*"good" + 0.009*"cheese" + 0.008*"{\ldots}" + 0.008*"\textbackslash{}'s" + 0.008*"n\textbackslash{}'t" + 0.007*"food" + 0.007*"onion" + 0.007*"place"'),
          (17,
           '0.012*"mandalay" + 0.012*"bay" + 0.011*"conference" + 0.011*"fountain" + 0.011*"elevator" + 0.011*"internet" + 0.009*"spacious" + 0.009*"\textasciitilde{}" + 0.009*"luxor" + 0.008*"fashion"'),
          (18,
           '0.007*"{\ldots}" + 0.007*"?" + 0.006*"suck" + 0.006*"tan" + 0.006*"awful" + 0.006*"``" + 0.006*"\textbackslash{}'\textbackslash{}'" + 0.006*"n\textbackslash{}'t" + 0.005*"rude" + 0.005*"spray"'),
          (19,
           '0.024*"beer" + 0.017*"bar" + 0.016*"great" + 0.013*"place" + 0.012*"food" + 0.011*"good" + 0.010*"\textbackslash{}'s" + 0.010*"game" + 0.010*"happy" + 0.009*"drink"'),
          (20,
           '0.041*"breakfast" + 0.021*"brunch" + 0.014*"omelet" + 0.013*"egg" + 0.013*"pancake" + 0.012*"great" + 0.012*"food" + 0.011*"mary" + 0.010*"place" + 0.010*"bloody"'),
          (21,
           '0.023*"sandwich" + 0.021*"pho" + 0.017*"bbq" + 0.012*"pork" + 0.010*"brisket" + 0.009*"good" + 0.009*"place" + 0.008*"\textbackslash{}'s" + 0.008*"rib" + 0.007*"meat"'),
          (22,
           '0.013*"donut" + 0.012*"park" + 0.009*"kid" + 0.008*"\textbackslash{}'s" + 0.007*"parking" + 0.007*"area" + 0.005*"place" + 0.005*"course" + 0.005*"great" + 0.005*"lot"'),
          (23,
           '0.022*"aria" + 0.021*"gaming" + 0.018*"m" + 0.018*"concert" + 0.017*"gilbert" + 0.017*"edinburgh" + 0.015*"st" + 0.014*"yuck" + 0.013*"bleu" + 0.013*"lazy"'),
          (24,
           '0.055*"sushi" + 0.033*"roll" + 0.012*"tuna" + 0.011*"fish" + 0.010*"place" + 0.010*"good" + 0.009*"fresh" + 0.009*"ayce" + 0.009*"chef" + 0.009*"great"'),
          (25,
           '0.010*"indian" + 0.010*"pasta" + 0.009*"food" + 0.008*"italian" + 0.008*"vegan" + 0.006*"vegetarian" + 0.006*"restaurant" + 0.006*"dish" + 0.006*"\textbackslash{}'s" + 0.006*")"'),
          (26,
           '0.047*"tire" + 0.039*"car" + 0.021*"carpet" + 0.020*"pastrami" + 0.019*"costco" + 0.017*"auto" + 0.017*"wash" + 0.016*"mcdonalds" + 0.015*"crew" + 0.013*"repair"'),
          (27,
           '0.072*"pizza" + 0.016*"wing" + 0.014*"crust" + 0.012*"good" + 0.011*"\textbackslash{}'s" + 0.009*"place" + 0.009*"slice" + 0.008*"great" + 0.008*"n\textbackslash{}'t" + 0.007*"chicago"'),
          (28,
           '0.017*"airport" + 0.009*"flight" + 0.008*"cab" + 0.007*"security" + 0.006*"driver" + 0.006*"bus" + 0.005*"gate" + 0.005*"n\textbackslash{}'t" + 0.005*"airline" + 0.004*"cabana"'),
          (29,
           '0.011*"u" + 0.011*"food" + 0.010*"n\textbackslash{}'t" + 0.009*"minute" + 0.008*"order" + 0.008*"table" + 0.008*"service" + 0.007*"did" + 0.007*"time" + 0.007*"{\ldots}"'),
          (30,
           '0.020*"ice" + 0.017*"cream" + 0.013*"chocolate" + 0.011*"tea" + 0.010*"flavor" + 0.009*"yogurt" + 0.007*"frozen" + 0.007*"\textbackslash{}'s" + 0.007*"place" + 0.006*"n\textbackslash{}'t"'),
          (31,
           '0.029*"guac" + 0.029*"lee" + 0.028*"wicked" + 0.027*"spoon" + 0.027*"bakery" + 0.025*"mi" + 0.022*"burro" + 0.021*"sirloin" + 0.019*"paradise" + 0.018*"takeout"'),
          (32,
           '0.026*"class" + 0.014*"na" + 0.011*"studio" + 0.009*"yoga" + 0.009*"instructor" + 0.008*"wan" + 0.008*"gon" + 0.007*"craft" + 0.006*"brewery" + 0.006*"teacher"'),
          (33,
           '0.028*"grocery" + 0.028*"gun" + 0.028*"target" + 0.025*"produce" + 0.023*"joe" + 0.019*"trader" + 0.019*"shoot" + 0.018*"david" + 0.018*"church" + 0.017*"knowledge"'),
          (34,
           '0.027*"el" + 0.025*"ive" + 0.022*"chris" + 0.021*"w" + 0.020*"wasnt" + 0.019*"torta" + 0.018*"im" + 0.017*"inn" + 0.016*"queso" + 0.015*"overrated"'),
          (35,
           '0.029*"coffee" + 0.011*"starbucks" + 0.010*"\textbackslash{}'s" + 0.009*"place" + 0.007*"latte" + 0.007*"great" + 0.006*")" + 0.006*"drink" + 0.006*"good" + 0.006*"like"'),
          (36,
           '0.030*"store" + 0.012*"shop" + 0.011*"\textbackslash{}'s" + 0.009*"selection" + 0.008*"item" + 0.008*"n\textbackslash{}'t" + 0.008*"price" + 0.008*"sale" + 0.007*"great" + 0.007*"buy"'),
          (37,
           '0.010*"chicken" + 0.010*"rice" + 0.009*"food" + 0.009*"noodle" + 0.008*"chinese" + 0.008*"soup" + 0.008*"dish" + 0.008*"good" + 0.008*"fried" + 0.007*"thai"'),
          (38,
           '0.011*"club" + 0.009*"\textbackslash{}'s" + 0.009*"drink" + 0.008*"n\textbackslash{}'t" + 0.008*"{\ldots}" + 0.008*"night" + 0.007*"bar" + 0.007*"place" + 0.007*")" + 0.006*"\$"'),
          (39,
           '0.013*"steak" + 0.009*"wine" + 0.008*"dinner" + 0.008*"food" + 0.008*"great" + 0.007*"restaurant" + 0.007*"good" + 0.006*"service" + 0.006*"meal" + 0.006*"lobster"'),
          (40,
           '0.016*"cake" + 0.012*"cupcake" + 0.006*"chocolate" + 0.006*"sweet" + 0.006*"red" + 0.006*")" + 0.006*"velvet" + 0.005*"(" + 0.005*"n\textbackslash{}'t" + 0.005*"{\ldots}"'),
          (41,
           '0.059*"buffet" + 0.018*"food" + 0.011*"crab" + 0.011*"prime" + 0.011*"dessert" + 0.011*"leg" + 0.011*"vega" + 0.010*"selection" + 0.010*"good" + 0.010*"seafood"'),
          (42,
           '0.043*"closed" + 0.018*"brake" + 0.017*"hangover" + 0.015*"cappuccino" + 0.014*"court" + 0.014*"bianco" + 0.014*"marquee" + 0.014*"dave" + 0.014*"quote" + 0.014*"bull"'),
          (43,
           '0.009*"n\textbackslash{}'t" + 0.009*"car" + 0.007*"\$" + 0.007*"did" + 0.007*"called" + 0.007*"time" + 0.006*"told" + 0.006*"\textbackslash{}'\textbackslash{}'" + 0.006*"``" + 0.006*"customer"'),
          (44,
           '0.056*"hair" + 0.031*"stylist" + 0.024*"cut" + 0.015*"sam" + 0.012*"laugh" + 0.012*"student" + 0.011*"a+" + 0.011*"defiantly" + 0.011*"university" + 0.011*"campus"'),
          (45,
           '0.028*"thai" + 0.026*"love" + 0.025*"food" + 0.020*"place" + 0.017*"great" + 0.016*"gym" + 0.015*"best" + 0.013*"service" + 0.012*"amazing" + 0.012*"excellent"'),
          (46,
           '0.033*"food" + 0.025*"good" + 0.023*"service" + 0.022*"great" + 0.018*"fast" + 0.016*"friendly" + 0.016*"place" + 0.014*"price" + 0.011*"bagel" + 0.011*"lunch"'),
          (47,
           '0.023*"nail" + 0.014*"salon" + 0.013*"job" + 0.012*"great" + 0.010*"professional" + 0.009*"time" + 0.009*"work" + 0.009*"did" + 0.009*"recommend" + 0.008*"pedicure"'),
          (48,
           '0.040*"*" + 0.024*"meatball" + 0.021*"gnocchi" + 0.019*"tapa" + 0.017*"blah" + 0.016*"sangria" + 0.016*"pharmacy" + 0.015*"overpriced" + 0.015*"caprese" + 0.015*"lasagna"'),
          (49,
           '0.016*"music" + 0.012*"cirque" + 0.011*"dancing" + 0.011*"fun" + 0.010*"stage" + 0.008*"vega" + 0.008*"act" + 0.008*"\textbackslash{}'s" + 0.008*"ticket" + 0.008*"band"')]
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}55}]:} \PY{c+c1}{\PYZsh{} Save LDA model to file if changed}
         \PY{k}{if}\PY{p}{(}\PY{n}{overwrite\PYZus{}saved\PYZus{}lda\PYZus{}model}\PY{p}{)}\PY{p}{:}
             \PY{n}{lda}\PY{o}{.}\PY{n}{save}\PY{p}{(}\PY{n}{PATH\PYZus{}WIP\PYZus{}LDA\PYZus{}MODEL}\PY{p}{)}
\end{Verbatim}


    \hypertarget{graphing-topics}{%
\subsubsection{Graphing Topics}\label{graphing-topics}}

\begin{itemize}
\item
\end{itemize}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}57}]:} \PY{o}{\PYZpc{}\PYZpc{}}\PY{k}{time}
         \PYZsh{} Prepare visualization
         vis = pyLDAvis.gensim.prepare(lda, corpus, dictionary)
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
CPU times: user 3min, sys: 1.41 s, total: 3min 1s
Wall time: 3min 4s

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}58}]:} \PY{c+c1}{\PYZsh{} Display visualization}
         \PY{n}{pyLDAvis}\PY{o}{.}\PY{n}{display}\PY{p}{(}\PY{n}{vis}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}58}]:} <IPython.core.display.HTML object>
\end{Verbatim}
            

    % Add a bibliography block to the postdoc
    
    
    
    \end{document}
