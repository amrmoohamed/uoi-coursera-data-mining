{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loganjtravis@gmail.com (Logan Travis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stdout\n",
    "\n",
    "# Imports; captures errors to supress warnings about changing\n",
    "# import syntax\n",
    "# from collections import OrderedDict\n",
    "import os, pickle, random\n",
    "import gensim.models as models, gensim.matutils as matutils, \\\n",
    "        gensim.corpora as corpora\n",
    "import matplotlib.pyplot as plot\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyLDAvis.gensim\n",
    "from scipy.sparse import load_npz, save_npz\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for repeatability\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set matplotlib to inline to preserve images in PDF\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "From course page [Week 2 > Task 2 Information > Task 2 Overview](https://www.coursera.org/learn/data-mining-project/supplement/0dtqy/task-2-overview):\n",
    "\n",
    "> The goal of this task is to mine the data set to construct a cuisine map to visually understand the landscape of different types of cuisines and their similarities. The cuisine map can help users understand what cuisines are available and their relations, which allows for the discovery of new cuisines, thus facilitating exploration of unfamiliar cuisines. You can see a [sample set of reviews](https://d396qusza40orc.cloudfront.net/dataminingcapstone/Task2Cuisines/cuisines.tar.gz) from all the restaurants for a cuisine, but you are strongly encouraged to experiment with your own set of cuisines if you have time.\n",
    ">\n",
    "> **Instructions**\n",
    "> Some questions to consider when building the cuisine map are the following:\n",
    "> \n",
    "> 1. What's the best way of representing a cuisine? If all we know about a cuisine is just the name, then there is nothing we can do. However, if we can associate a cuisine with the restaurants offering the cuisine and all the information about the restaurants, particularly reviews, then we will have a basis to characterize cuisines and assess their similarity. Since review text contains a lot of useful information about a cuisine, a natural question is: what's the best way to represent a cuisine with review text data? Are some words more important in representing a cuisine than others?\n",
    "> 2. What's the best way of computing the similarity of two cuisines? Assuming that two cuisines can each be represented by their corresponding reviews, how should we compute their similarity?\n",
    "> 3. What's the best way of clustering cuisines? Clustering of cuisines can help reveal major categories of cuisines. How would the number of clusters impact the utility of your results for understanding cuisine categories? How does a clustering algorithm affect the visualization of the cuisine map?\n",
    "> 4. Is your cuisine map actually useful to at least some people? In what way? If it's not useful, how might you be able to improve it to make it more useful?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grading Rubric\n",
    "\n",
    "From course page [Week 2 > Task 2 Information > Task 2 Rubric](https://www.coursera.org/learn/data-mining-project/supplement/oE476/task-2-rubric):\n",
    "\n",
    "> | Criteria | Poor (1 point) | Fair (3 points) | Good (5 points) | Excellent (6 points) |\n",
    "> | --- | --- | --- | --- | --- |\n",
    "> | **Task 2.1: Visualization of Cuisine Map** | The visualization is either absent or useless. | The visualization is present but does not make clear the similarity of cuisines. | The visualization clearly shows what cuisines are similar, but the description of the visualization is poor. | The visualization clearly shows what cuisines are similar, and the description of the visualization is thorough. |\n",
    "> | **Task 2.2: Improving Cuisine Map** | The visualizations are either absent or useless. | The visualizations are present but do not make clear the similarity of cuisines. No descriptions of improvements over Task 2.1. | The visualizations clearly show what cuisines are similar. There is a description of the visualization improvements. | The visualizations clearly show what cuisines are similar. There is in-depth analysis/description about the visualization improvements. |\n",
    "> | **Task 2.3: Incorporating Clustering in Cuisine Map** | The visualization is either absent or useless. | The visualization does not make clear how clustering was incorporated. | The visualization makes clear how clustering was incorporated but does not describe multiple clustering algorithms for visualization. | The visualization makes clear how clustering was incorporated and describes multiple clustering algorithms for visualization. |\n",
    "> | **Written Report** | Report of the results is not present. | The description is not detailed enough to allow replication of work. | The description is detailed enough to allow replication of work. No analysis of the results is present. | The description is detailed enough to allow replication of work. Thorough analysis of the results and insights on the cuisine data are present. |\n",
    "> | **Visualizations: Appropriateness of choice** | The visualization method is not suitable for the type of data. | The visualization method is suitable for the type of data, but another way to visualize the data is clearly better. | The visualization method used is quite suitable for the type of data and makes relationships clear. | Extra effort was made to make the visualizations beautifully designed and/or usefully interactive. |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Yelp Review Data Set\n",
    "\n",
    "I cleaned the Yelp review data and extraced cuisines from the business data set separate notebooks. Loading saved data to shorten this report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set paths to data source, work in process (\"WIP\"), and output\n",
    "PATH_SOURCE = \"source/\"\n",
    "PATH_WIP = \"wip/\"\n",
    "PATH_OUTPUT = \"output/\"\n",
    "\n",
    "# Set file paths\n",
    "PATH_SOURCE_YELP_REVIEWS = PATH_SOURCE + \\\n",
    "        \"yelp_academic_dataset_review.pkl.gzip\"\n",
    "PATH_SOURCE_YELP_CUISINES = PATH_SOURCE + \"yelp_academic_dataset_cuisine.csv\"\n",
    "PATH_SOURCE_YELP_REST_TO_CUISINES = PATH_SOURCE + \\\n",
    "        \"yelp_academic_dataset_restaurant_to_cuisine.pkl.gzip\"\n",
    "# PATH_WIP_TOKENIZER = PATH_WIP + \"task01_tokenizer.pkl\"\n",
    "# PATH_WIP_TOKEN_MATRIX = PATH_WIP + \"task01_token_matrix.npz\"\n",
    "# PATH_WIP_LDA_MODEL = PATH_WIP + \"task01_lda_model\"\n",
    "# PATH_WIP_LDA_MODEL_VIS = PATH_WIP + \"task01_lda_model.html\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read saved data\n",
    "dfYelpReviews = pd.read_pickle(PATH_SOURCE_YELP_REVIEWS)\n",
    "dfYelpRestToCuis = pd.read_pickle(PATH_SOURCE_YELP_REST_TO_CUISINES)\n",
    "cuisines = pd.read_csv(PATH_SOURCE_YELP_CUISINES, names=[\"cuisine\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join (inner) reviews to restaurants\n",
    "dfYelpReviews = dfYelpReviews.join(dfYelpRestToCuis, \\\n",
    "                                   on=\"business_id\", \\\n",
    "                                   how=\"inner\", \\\n",
    "                                   rsuffix=\"_business\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (706646, 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>date</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>type</th>\n",
       "      <th>user_id</th>\n",
       "      <th>votes_cool</th>\n",
       "      <th>votes_funny</th>\n",
       "      <th>votes_useful</th>\n",
       "      <th>categories</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>review_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>I7Kte2FwXWPCwdm7ispu1A</th>\n",
       "      <td>JwUE5GmEO-sH1FuwJgKBlQ</td>\n",
       "      <td>2008-07-07</td>\n",
       "      <td>4</td>\n",
       "      <td>Pretty good dinner with a nice selection of fo...</td>\n",
       "      <td>review</td>\n",
       "      <td>zvNimI98mrmhgNOOrzOiGg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[Food]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9uHZyOu5CTCDl1L6cfvOCA</th>\n",
       "      <td>JwUE5GmEO-sH1FuwJgKBlQ</td>\n",
       "      <td>2009-05-03</td>\n",
       "      <td>4</td>\n",
       "      <td>Good truck stop dining at the right price. We ...</td>\n",
       "      <td>review</td>\n",
       "      <td>p4ySEi8PEli0auZGBsy6gA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[Food]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ow1c4Lcl3ObWxDC2yurwjQ</th>\n",
       "      <td>JwUE5GmEO-sH1FuwJgKBlQ</td>\n",
       "      <td>2009-05-04</td>\n",
       "      <td>4</td>\n",
       "      <td>If you like lot lizards, you'll love the Pine ...</td>\n",
       "      <td>review</td>\n",
       "      <td>ZYaumz29bl9qHpu-KVtMGA</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>[Food]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FRTCszJWkJonDAZx3yr8FA</th>\n",
       "      <td>JwUE5GmEO-sH1FuwJgKBlQ</td>\n",
       "      <td>2010-10-30</td>\n",
       "      <td>4</td>\n",
       "      <td>Enjoyable experience for the whole family. The...</td>\n",
       "      <td>review</td>\n",
       "      <td>SvS7NXWG2B2kFoaHaWdGfg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[Food]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qQIvtbqUujvvnJDzPSfmFA</th>\n",
       "      <td>JwUE5GmEO-sH1FuwJgKBlQ</td>\n",
       "      <td>2011-02-06</td>\n",
       "      <td>4</td>\n",
       "      <td>One of my favorite truck stop diners with soli...</td>\n",
       "      <td>review</td>\n",
       "      <td>qOYI9O0ecMJ9VaqcM9phNw</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[Food]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   business_id       date  stars  \\\n",
       "review_id                                                          \n",
       "I7Kte2FwXWPCwdm7ispu1A  JwUE5GmEO-sH1FuwJgKBlQ 2008-07-07      4   \n",
       "9uHZyOu5CTCDl1L6cfvOCA  JwUE5GmEO-sH1FuwJgKBlQ 2009-05-03      4   \n",
       "ow1c4Lcl3ObWxDC2yurwjQ  JwUE5GmEO-sH1FuwJgKBlQ 2009-05-04      4   \n",
       "FRTCszJWkJonDAZx3yr8FA  JwUE5GmEO-sH1FuwJgKBlQ 2010-10-30      4   \n",
       "qQIvtbqUujvvnJDzPSfmFA  JwUE5GmEO-sH1FuwJgKBlQ 2011-02-06      4   \n",
       "\n",
       "                                                                     text  \\\n",
       "review_id                                                                   \n",
       "I7Kte2FwXWPCwdm7ispu1A  Pretty good dinner with a nice selection of fo...   \n",
       "9uHZyOu5CTCDl1L6cfvOCA  Good truck stop dining at the right price. We ...   \n",
       "ow1c4Lcl3ObWxDC2yurwjQ  If you like lot lizards, you'll love the Pine ...   \n",
       "FRTCszJWkJonDAZx3yr8FA  Enjoyable experience for the whole family. The...   \n",
       "qQIvtbqUujvvnJDzPSfmFA  One of my favorite truck stop diners with soli...   \n",
       "\n",
       "                          type                 user_id  votes_cool  \\\n",
       "review_id                                                            \n",
       "I7Kte2FwXWPCwdm7ispu1A  review  zvNimI98mrmhgNOOrzOiGg           0   \n",
       "9uHZyOu5CTCDl1L6cfvOCA  review  p4ySEi8PEli0auZGBsy6gA           0   \n",
       "ow1c4Lcl3ObWxDC2yurwjQ  review  ZYaumz29bl9qHpu-KVtMGA           0   \n",
       "FRTCszJWkJonDAZx3yr8FA  review  SvS7NXWG2B2kFoaHaWdGfg           0   \n",
       "qQIvtbqUujvvnJDzPSfmFA  review  qOYI9O0ecMJ9VaqcM9phNw           0   \n",
       "\n",
       "                        votes_funny  votes_useful categories  \n",
       "review_id                                                     \n",
       "I7Kte2FwXWPCwdm7ispu1A            0             1     [Food]  \n",
       "9uHZyOu5CTCDl1L6cfvOCA            0             0     [Food]  \n",
       "ow1c4Lcl3ObWxDC2yurwjQ            6             0     [Food]  \n",
       "FRTCszJWkJonDAZx3yr8FA            0             0     [Food]  \n",
       "qQIvtbqUujvvnJDzPSfmFA            0             0     [Food]  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print dataframe shape and head\n",
    "print(f\"Shape: {dfYelpReviews.shape}\")\n",
    "dfYelpReviews.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Determine Cuisine Similarity via Term Frequencies (no IDF)\n",
    "\n",
    "*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF Parameters\n",
    "\n",
    "I found the settings below worked well when extracting topics for the week one assignment:\n",
    "\n",
    "* Limit maximum terms. This is an extreme upper limit. The SciKit Learn `TfidfVectorizer` class ([link to documentation](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html)) never yielded more than 5,000 terms based on my other parameters. Most runs identified approx. 1,000 terms.\n",
    "* Exclude terms appearing in more than 50% of documents. These add little value for differntiating topics.\n",
    "* Exclude terms appearing in less than 1% of documents. I tested many settings for this parameter ranging down to 2 documents and up to 10% of all documents. The Yelp reviews include numerious limited-use terms (e.g., people and place names) and I found it difficult to interpret the topics with too many present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set token limit\n",
    "MAX_FEATURES = 10000\n",
    "\n",
    "# Set document frequency ceiling; topic analysis will ignore\n",
    "# words found in more documents\n",
    "MAX_DF = 0.5\n",
    "\n",
    "# Set document frequency floor; topic analysis will ignore\n",
    "# words found in fewer document\n",
    "MIN_DF = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyTokenizer:\n",
    "    def __init__(self):\n",
    "        \"\"\"String tokenizer utilizing lemmatizing and stemming.\"\"\"\n",
    "        self.wnl = nltk.stem.WordNetLemmatizer()\n",
    "    \n",
    "    def __call__(self, document):\n",
    "        \"\"\"Return tokens from a string.\"\"\"\n",
    "        return [self.wnl.lemmatize(token) for \\\n",
    "                        token in nltk.word_tokenize(document)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Excessive Data Set Size\n",
    "\n",
    "Setting parameters to limit excessively in/frequent tokens helped to manage overall data size. Unfortunately, both proved insufficient to permit the LDA model to fit within the memory available on my machine. I therefore worked on a 30% sample of the Yelp review data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set working dataframe to a 30% sample of the full data set;\n",
    "# too large otherwise\n",
    "df = dfYelpReviews.sample(frac=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create TF vectorizer \n",
    "tf = TfidfVectorizer(max_features=MAX_FEATURES, max_df=MAX_DF, min_df=MIN_DF, \\\n",
    "                     stop_words=\"english\", use_idf=False, tokenizer=MyTokenizer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 38s, sys: 453 ms, total: 1min 38s\n",
      "Wall time: 1min 39s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Calculate term frequencies\n",
    "docTerms = tf.fit_transform(df.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 865 tokens in 70,665 documents\n"
     ]
    }
   ],
   "source": [
    "# Print token matrix shape\n",
    "print(\"Found {0[1]:,} tokens in {0[0]:,} documents\".format(docTerms.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sum TFs by Cuisine\n",
    "\n",
    "*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
