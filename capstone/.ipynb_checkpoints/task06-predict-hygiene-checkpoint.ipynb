{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loganjtravis@gmail.com (Logan Travis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "tags": [
     "hide_cell"
    ]
   },
   "outputs": [],
   "source": [
    "%%capture --no-stdout\n",
    "\n",
    "# Imports; captures errors to supress warnings about changing\n",
    "# import syntax\n",
    "import matplotlib.pyplot as plot\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "hide_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Set random seed for repeatability\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "hide_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Set matplotlib to inline to preserve images in PDF\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "From course page [Week 5 > Task 6 Information > Task 6 Overview](https://www.coursera.org/learn/data-mining-project/supplement/gvCsC/task-4-and-5-overview):\n",
    "\n",
    "> In this task, you are going to predict whether a set of restaurants will pass the public health inspection tests given the corresponding Yelp text reviews along with some additional information such as the locations and cuisines offered in these restaurants. Making a prediction about an unobserved attribute using data mining techniques represents a wide range of important applications of data mining. Through working on this task, you will gain direct experience with such an application. Due to the flexibility of using as many indicators for prediction as possible, this would also give you an opportunity to potentially combine many different algorithms you have learned from the courses in the Data Mining Specialization to solve a real world problem and experiment with different methods to understand whatâ€™s the most effective way of solving the problem.\n",
    "> \n",
    "> **About the Dataset**\n",
    "You should first [download the dataset](https://d396qusza40orc.cloudfront.net/dataminingcapstone/Task6/Hygiene.tar.gz). The dataset is composed of a training subset containing 546 restaurants used for training your classifier, in addition to a testing subset of 12753 restaurants used for evaluating the performance of the classifier. In the training subset, you will be provided with a binary label for each restaurant, which indicates whether the restaurant has passed the latest public health inspection test or not, whereas for the testing subset, you will not have access to any labels. The dataset is spread across three files such that the first 546 lines in each file correspond to the training subset, and the rest are part of the testing subset. Below is a description of each file:\n",
    ">\n",
    "> * hygiene.dat: Each line contains the concatenated text reviews of one restaurant.\n",
    "> * hygiene.dat.labels: For the first 546 lines, a binary label (0 or 1) is used where a 0 indicates that the restaurant has passed the latest public health inspection test, while a 1 means that the restaurant has failed the test. The rest of the lines have \"[None]\" in their label field implying that they are part of the testing subset.\n",
    "> * hygiene.dat.additional: It is a CSV (Comma-Separated Values) file where the first value is a list containing the cuisines offered, the second value is the zip code, which gives an idea about the location, the third is the number of reviews, and the fourth is the average rating, which can vary between 0 and 5 (5 being the best)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Note on The Training Data\n",
    "\n",
    "I realized after building my second predict model that I may have incorrectly interpretted the meaning of `hygiene.data.labels`. The assigment states, \"...a 0 indicates that the restaurant has passed the latest public health inspection test, while a 1 means that the restaurant has failed the test.\" It does not indicate the immediacy (in time) of those last inspections. A restaurant might have failed its hygiene inspection only days before compiling the data set as easily as another restaurant passed an ispection from years ago. Also, the reviews lack time indicators so a restaurant's reviews might include reviews from a decade ago when it failed a hygiene inspection. How those potentially negative reviews affect the predicition of future failure would depend on many factor.\n",
    "\n",
    "**In short:** I recommend tempering expectations for accurrate prediction. Even if a model works, it will necessarily overfit to the nuances of this training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictive Model 01: Unigrams and Logistic Regression\n",
    "\n",
    "I start by representing text as a unigram vector then applying logistic regression. This predictive model gives a useful baseline for future methods. It also highlights the difficulty of the prediction: Logistic regression alone proves an *incredibly* poor predictor!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "hide_cell"
    ]
   },
   "source": [
    "## Prepare Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "tags": [
     "hide_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Set paths to data source, work in process (\"WIP\"), and output\n",
    "PATH_SOURCE = \"source\"\n",
    "PATH_WIP = \"wip\"\n",
    "PATH_OUTPUT = \"output\"\n",
    "\n",
    "# Set file paths\n",
    "PATH_SOURCE_TRAIN_TEXT = f\"{PATH_SOURCE}/Hygiene/train_hygiene.dat\"\n",
    "PATH_SOURCE_TRAIN_LABELS = f\"{PATH_SOURCE}/Hygiene/train_hygiene.dat.labels\"\n",
    "PATH_SOURCE_TRAIN_REST = f\"{PATH_SOURCE}/Hygiene/train_hygiene.dat.additional\"\n",
    "PATH_SOURCE_TARGET_TEXT = f\"{PATH_SOURCE}/Hygiene/target_hygiene.dat\"\n",
    "PATH_SOURCE_TARGET_REST = f\"{PATH_SOURCE}/Hygiene/target_hygiene.dat.additional\"\n",
    "\n",
    "# Set paths to AutoPhrase output\n",
    "AUTOPHRASE_LOG = \"AutoPhrase/models/hygiene/log.txt\"\n",
    "AUTOPHRASE_RESULTS = \"AutoPhrase/models/hygiene/AutoPhrase.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": [
     "hide_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Get training text and labels\n",
    "with open(PATH_SOURCE_TRAIN_TEXT) as f:\n",
    "    arrTrainText = [l.rstrip() for l in f]\n",
    "with open(PATH_SOURCE_TRAIN_LABELS) as f:\n",
    "    arrTrainLabels = [l.rstrip() == \"1\" for l in f]\n",
    "dfTrain = pd.DataFrame(data={\"failed_hygiene\": arrTrainLabels, \"review_text\": arrTrainText})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": [
     "hide_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Split data into training and testing sets\n",
    "dfTrain[\"review_text_len\"] = dfTrain.review_text.str.len()\n",
    "dfTrain, dfTest = train_test_split(dfTrain, test_size=0.3, random_state=84)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": [
     "hide_cell"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>failed_hygiene</th>\n",
       "      <th>review_text</th>\n",
       "      <th>review_text_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>463</th>\n",
       "      <td>True</td>\n",
       "      <td>Lovely place! Great neighborhood feel, excelle...</td>\n",
       "      <td>17352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>False</td>\n",
       "      <td>The Crab Spring rolls were absolutely amazing!...</td>\n",
       "      <td>12390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>False</td>\n",
       "      <td>We went about a year ago... the experience was...</td>\n",
       "      <td>3107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>False</td>\n",
       "      <td>I was expecting a lot more given all the great...</td>\n",
       "      <td>2566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>False</td>\n",
       "      <td>This joint became a regular stop for us when w...</td>\n",
       "      <td>4765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545</th>\n",
       "      <td>False</td>\n",
       "      <td>A for effort. If you happen to be stuck with s...</td>\n",
       "      <td>18692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>True</td>\n",
       "      <td>Eat breakfast here.This restaurant has one of ...</td>\n",
       "      <td>4837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>False</td>\n",
       "      <td>I was going to watch a movie at SIFF but wante...</td>\n",
       "      <td>9730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>True</td>\n",
       "      <td>All I had here were cha sao bao (BBQ pork buns...</td>\n",
       "      <td>4814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>False</td>\n",
       "      <td>One of the best Phillies in the city. Service ...</td>\n",
       "      <td>326</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     failed_hygiene                                        review_text  \\\n",
       "463            True  Lovely place! Great neighborhood feel, excelle...   \n",
       "240           False  The Crab Spring rolls were absolutely amazing!...   \n",
       "461           False  We went about a year ago... the experience was...   \n",
       "257           False  I was expecting a lot more given all the great...   \n",
       "407           False  This joint became a regular stop for us when w...   \n",
       "545           False  A for effort. If you happen to be stuck with s...   \n",
       "465            True  Eat breakfast here.This restaurant has one of ...   \n",
       "331           False  I was going to watch a movie at SIFF but wante...   \n",
       "381            True  All I had here were cha sao bao (BBQ pork buns...   \n",
       "66            False  One of the best Phillies in the city. Service ...   \n",
       "\n",
       "     review_text_len  \n",
       "463            17352  \n",
       "240            12390  \n",
       "461             3107  \n",
       "257             2566  \n",
       "407             4765  \n",
       "545            18692  \n",
       "465             4837  \n",
       "331             9730  \n",
       "381             4814  \n",
       "66               326  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect first 10 rows\n",
    "dfTrain.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": [
     "hide_cell"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>review_text</th>\n",
       "      <th colspan=\"2\" halign=\"left\">review_text_len</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>failed_hygiene</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>195</td>\n",
       "      <td>7276.015385</td>\n",
       "      <td>10327.798184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>187</td>\n",
       "      <td>9967.219251</td>\n",
       "      <td>12589.871449</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               review_text review_text_len              \n",
       "                     count            mean           std\n",
       "failed_hygiene                                          \n",
       "False                  195     7276.015385  10327.798184\n",
       "True                   187     9967.219251  12589.871449"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sanity check on training versus testing split\n",
    "dfTrain.groupby([\"failed_hygiene\"]).agg({\n",
    "    \"review_text\": [\"count\"],\n",
    "    \"review_text_len\": [\"mean\", \"std\"]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": [
     "hide_cell"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>review_text</th>\n",
       "      <th colspan=\"2\" halign=\"left\">review_text_len</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>failed_hygiene</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>78</td>\n",
       "      <td>6230.256410</td>\n",
       "      <td>8406.959927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>86</td>\n",
       "      <td>9252.313953</td>\n",
       "      <td>10821.455737</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               review_text review_text_len              \n",
       "                     count            mean           std\n",
       "failed_hygiene                                          \n",
       "False                   78     6230.256410   8406.959927\n",
       "True                    86     9252.313953  10821.455737"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sanity check on training versus testing split\n",
    "dfTest.groupby([\"failed_hygiene\"]).agg({\n",
    "    \"review_text\": [\"count\"],\n",
    "    \"review_text_len\": [\"mean\", \"std\"]\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Unigram Probability Matrix\n",
    "\n",
    "I chose not to use IDF weighting because the data concatenated all reviews for a single restaurant with no delimiter to split them. Instead I count terms then normalize appearances for each restaurant creating a term probability matrix. A couple upfront comments:\n",
    "\n",
    "* Logistic regression works best when the number of samples far exceeds the number of variables. That is not the case for this data set. I expect very poor performance with high sensitivity to model parameters.\n",
    "* I did not tune the term vectorizer; it includes all terms found in the training data.\n",
    "* I will tune the parameters in the next model. I intend this model as a *naive* baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": [
     "hide_cell"
    ]
   },
   "outputs": [],
   "source": [
    "class MyTokenizer:\n",
    "    def __init__(self):\n",
    "        \"\"\"String tokenizer utilizing lemmatizing and stemming.\"\"\"\n",
    "        self.wnl = nltk.stem.WordNetLemmatizer()\n",
    "    \n",
    "    def __call__(self, document):\n",
    "        \"\"\"Return tokens from a string.\"\"\"\n",
    "        return [self.wnl.lemmatize(token) for \\\n",
    "                        token in nltk.word_tokenize(document)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": [
     "hide_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Create TF vectorizer \n",
    "tf = CountVectorizer(max_df=1.0, min_df=1, \\\n",
    "                     stop_words=\"english\", \\\n",
    "                     tokenizer=MyTokenizer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.39 s, sys: 344 ms, total: 7.73 s\n",
      "Wall time: 7.86 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Calculate training term frequencies\n",
    "trainTerms = tf.fit_transform(dfTrain.review_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "382 restaurant reviews extracted into 23,107 unigram terms.\n"
     ]
    }
   ],
   "source": [
    "# Normalize for each restaurant\n",
    "trainP = trainTerms / trainTerms.sum(axis=1)\n",
    "print(\"{:,} restaurant reviews extracted into {:,} unigram terms.\".format(*trainP.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": [
     "hide_cell"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.45 s, sys: 15.6 ms, total: 2.47 s\n",
      "Wall time: 2.49 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Calculate testing term frequences; Note: Transform ONLY,\n",
    "# no additional fitting\n",
    "testTerms = tf.transform(dfTest.review_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": [
     "hide_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Normalize for each restaurant\n",
    "testP = testTerms / testTerms.sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": [
     "hide_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Create logistic regression model\n",
    "model_TF_LR = LogisticRegression(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 62.5 ms, sys: 0 ns, total: 62.5 ms\n",
      "Wall time: 25.1 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Train logistic regression model\n",
    "model_TF_LR = model_TF_LR.fit(trainP, dfTrain.failed_hygiene)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printModelF1(truth, prediction, modelName, includeConfusionMatrix=True):\n",
    "    \"\"\"Print model quality using specified measure.\"\"\"\n",
    "    f1 = f1_score(truth, prediction)\n",
    "    print(\"{}\\n-----\\nF-1 Score: {:.6f}\".format(modelName, f1))\n",
    "    if(includeConfusionMatrix):\n",
    "        cm = confusion_matrix(truth, prediction)\n",
    "        print(\"True Negatives: {0:,}\\nTrue Positives: {3:,}\\nFalse Negatives: {2:,}\\nFalse Positives: {1:,}\".format(*cm.ravel()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 01 Logistic Regression of Term Probabilities\n",
      "-----\n",
      "F-1 score: 0.000000\n",
      "True Negatives: 77\n",
      "True Positives: 0\n",
      "False Negatives: 86\n",
      "False Positives: 1\n"
     ]
    }
   ],
   "source": [
    "# Calucalate F1 score\n",
    "model_TF_LR_Pred = model_TF_LR.predict(testP)\n",
    "printModelF1(dfTest.failed_hygiene, model_TF_LR_Pred, \\\n",
    "             \"Model 01 Logistic Regression of Term Probabilities\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The simple logistic regression performed *horribly*. It only predict **one** failed hygiene inspection in the test data and that was a false positive. Review text simply includes too much noise. While we would anticipate hygiene issues to appear in reviews, we should also expect them to drown in a sea of non-hygiene related reviews about the food, service, location, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictive Model 02: Recursive Feature Elimination of  Unigrams Before Logistic Regression\n",
    "\n",
    "I next try a feature selection method called Recursive Feature Elimination ([`RFE` on SciKit Learn](http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFE.html#sklearn.feature_selection.RFE.get_support)). The 22,000+ terms found in the training data far exceed the training sample (382). If a simple logistic regession has predictive value, it first needs to train on only the most useful features. I therefore find the 30 top ranked (by RFE) as a starting point to see what improvements logistic regression has to offer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find Most Predictive Terms using RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": [
     "hide_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Create logistic regression model for RFE\n",
    "model_TF_LR_RFE = LogisticRegression(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": [
     "hide_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Create Recursive Feature Elimination instance\n",
    "rfe_TF_LR_RFE = RFE(model_TF_LR_RFE, n_features_to_select=30, step=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 11s, sys: 16.9 s, total: 1min 28s\n",
      "Wall time: 28.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Reduce features using Recursive Feature Elimination\n",
    "rfe_TF_LR_RFE = rfe_TF_LR_RFE.fit(trainP, dfTrain.failed_hygiene)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restrict training terms to best from RFE and calculate new\n",
    "# relative probabilities\n",
    "trainTerms_RFE = trainTerms[:, rfe_TF_LR_RFE.get_support(indices=True)]\n",
    "trainP_RFE = trainTerms_RFE / trainTerms_RFE.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": [
     "hide_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Restrict testing terms to best from RFE and calculate new\n",
    "# relative probabilities\n",
    "testTerms_RFE = testTerms[:, rfe_TF_LR_RFE.get_support(indices=True)]\n",
    "testP_RFE = testTerms_RFE / testTerms_RFE.sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Logistic Regression Model after RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 1.61 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Train logistic regression model\n",
    "model_TF_LR_RFE = model_TF_LR_RFE.fit(trainP_RFE, dfTrain.failed_hygiene)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 02 Logistic Regression of Term Probabilities after RFE\n",
      "-----\n",
      "F-1 score: 0.442857\n",
      "True Negatives: 55\n",
      "True Positives: 31\n",
      "False Negatives: 55\n",
      "False Positives: 23\n"
     ]
    }
   ],
   "source": [
    "# Calucalate F1 score\n",
    "model_TF_LR_RFE_Pred = model_TF_LR_RFE.predict(testP_RFE)\n",
    "printModelF1(dfTest.failed_hygiene, model_TF_LR_RFE_Pred, \\\n",
    "             \"Model 02 Logistic Regression of Term Probabilities after RFE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restricting the logistic model to the 100 best terms improves its performance significantly. Tuning the best terms - whether with RFE or earlier in the count vectorizer - might improve prediction quality further."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 03: Latent Symantic Analysis of  Unigrams Before Logistic Regression\n",
    "\n",
    "RFE selects the best features from an existing data set. Those features it removes do not predict *as well* as the features it keeps but they can still have predictive value. I therefore try a feature decomposition method called Latent Symantic Analysis ([`TruncatedSVD` in SciKit Learn](http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.TruncatedSVD.html#sklearn.decomposition.TruncatedSVD)). The decomposition process still reduces the number of features - useful for logistic regression - but does so by linear combination of those features. Some ability to explain variation still gets loss. Usually much less than feature selection.\n",
    "\n",
    "I tuned the number of decomposed features to 180. LSA frequently starts with 100 but I find - through trial and error - 180 produced the best results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": [
     "hide_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Create Latent Semantic Analysis instance\n",
    "lsa = TruncatedSVD(n_components=180, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.22 s, sys: 1.12 s, total: 6.34 s\n",
      "Wall time: 2.16 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Perform Latent Semantic Analysis on training terms\n",
    "decomp_LSA = lsa.fit(trainTerms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the raw trainging term counts into the\n",
    "# LSA decomposed features\n",
    "trainTermsLSA = decomp_LSA.transform(trainTerms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "tags": [
     "hide_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Transform the raw testing term counts into the\n",
    "# LSA decomposed features\n",
    "testTermsLSA = decomp_LSA.transform(testTerms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": [
     "hide_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Create logistic regression model from LSA\n",
    "model_LSA_LR = LogisticRegression(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 46.9 ms, sys: 0 ns, total: 46.9 ms\n",
      "Wall time: 51.1 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Train logistic regression model on LSA features\n",
    "model_LSA_LR = model_LSA_LR.fit(trainTermsLSA, dfTrain.failed_hygiene)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 03 Logistic Regression of LSA from Term Frequencies\n",
      "-----\n",
      "F-1 score: 0.674419\n",
      "True Negatives: 50\n",
      "True Positives: 58\n",
      "False Negatives: 28\n",
      "False Positives: 28\n"
     ]
    }
   ],
   "source": [
    "# Calucalate F1 score\n",
    "model_LSA_LR_Pred = model_LSA_LR.predict(testTermsLSA)\n",
    "printModelF1(dfTest.failed_hygiene, model_LSA_LR_Pred, \\\n",
    "             \"Model 03 Logistic Regression of LSA from Term Frequencies\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression of LSA components yieled good predictive value (within the limits of this training data). I would consider recommending it to a county hygiene inspector especially one with more restaurants to inspect than time. It has a higher false negative rate than ideal **but** the method scales well. After initial training, a predictive pipeline could parallelize across restaurants thanks to:\n",
    "\n",
    "* Simple term count as opposed to IDF weighting that requires evaluation over an entire corpus\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 04: Latent Symantic Analysis of Frequent Phrases before Logistic Regression\n",
    "\n",
    "*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I ran [AutoPhrase](https://github.com/shangjingbo1226/AutoPhrase) with custom `MODEL`, `RAW_TRAIN`, and `RAW_LABEL_FILE` parameters to train it agains the Yelp reviews for Mexican restaurants and the expert labels. Full command:\n",
    "\n",
    "```bash\n",
    "MODEL='./models/hygiene' RAW_TRAIN='./wip/train_hygiene.dat' RAW_LABEL_FILE='./wip/train_hygiene.dat.labels' ./auto_phrase.sh 2>&1 | tee ./models/hygiene/log.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m===Compilation===\u001b(B\u001b[m\n",
      "\u001b[32m===Tokenization===\u001b(B\u001b[m\n",
      "Current step: Tokenizing input file...\u001b[0K\n",
      "real\t0m1.996s\n",
      "user\t0m5.688s\n",
      "sys\t0m0.797s\n",
      "Detected Language: EN\u001b[0K\n",
      "Current step: Tokenizing stopword file...\u001b[0K\n",
      "Current step: Tokenizing wikipedia phrases...\u001b[0K\n",
      "Current step: Tokenizing expert labels...\u001b[0K\n",
      "com.cybozu.labs.langdetect.LangDetectException: no features in text\n",
      "\tat com.cybozu.labs.langdetect.Detector.detectBlock(Detector.java:235)\n",
      "\tat com.cybozu.labs.langdetect.Detector.getProbabilities(Detector.java:221)\n",
      "\tat com.cybozu.labs.langdetect.Detector.detect(Detector.java:209)\n",
      "\tat Tokenizer.detectLanguage(Tokenizer.java:151)\n",
      "\tat Tokenizer.main(Tokenizer.java:824)\n",
      "Using default setting for unknown languages...\n",
      "Using default setting for unknown languages...\n",
      "Using default setting for unknown languages...\n",
      "Using default setting for unknown languages...\n",
      "Using default setting for unknown languages...\n",
      "\u001b[32m===Part-Of-Speech Tagging===\u001b(B\u001b[m\n",
      "Current step: Splitting files...\u001b[0K\n",
      "Current step: Tagging...\u001b[0K\n",
      "Current step: Merging...\u001b[0K\n",
      "\u001b[32m===AutoPhrasing===\u001b(B\u001b[m\n",
      "=== Current Settings ===\n",
      "Iterations = 2\n",
      "Minimum Support Threshold = 10\n",
      "Maximum Length Threshold = 6\n",
      "POS-Tagging Mode Enabled\n",
      "Number of threads = 10\n",
      "Labeling Method = DPDN\n",
      "\tAuto labels from knowledge bases\n",
      "\tMax Positive Samples = -1\n",
      "=======\n",
      "Loading data...\n",
      "# of total tokens = 1024854\n",
      "max word token id = 27087\n",
      "# of documents = 546\n",
      "# of distinct POS tags = 57\n",
      "Mining frequent phrases...\n",
      "selected MAGIC = 27091\n",
      "# of frequent phrases = 34509\n",
      "Extracting features...\n",
      "Constructing label pools...\n",
      "\tThe size of the positive pool = 3409\n",
      "\tThe size of the negative pool = 30845\n",
      "# truth patterns = 49379\n",
      "Estimating Phrase Quality...\n",
      "Segmenting...\n",
      "Rectifying features...\n",
      "Estimating Phrase Quality...\n",
      "Segmenting...\n",
      "Dumping results...\n",
      "Done.\n",
      "\n",
      "real\t0m8.071s\n",
      "user\t0m18.734s\n",
      "sys\t0m3.109s\n",
      "\u001b[32m===Saving Model and Results===\u001b(B\u001b[m\n",
      "\u001b[32m===Generating Output===\u001b(B\u001b[m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print AutoPhrase log file\n",
    "with open(AUTOPHRASE_LOG, \"r\") as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "tags": [
     "hide_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Read AutoPhrase frequent phrases into dataframe\n",
    "dfPhrases = pd.read_csv(AUTOPHRASE_RESULTS, sep=\"\\t\", \\\n",
    "                        names=[\"score\", \"phrase\"], index_col=\"phrase\")\n",
    "dfPhrases.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "tags": [
     "hide_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Convert phrase dataframe to vocabulary dictionary for\n",
    "# use in `CountVectorizer`\n",
    "phrases = dfPhrases.phrase.to_dict() # {index:dish}\n",
    "phrases = {v: k for k, v in phrases.items()} # {dish:index}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "tags": [
     "hide_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Create phrase frequency vectorizer \n",
    "pf = CountVectorizer(max_df=1.0, min_df=1, \\\n",
    "                     stop_words=\"english\", \\\n",
    "                     tokenizer=MyTokenizer(), \\\n",
    "                     vocabulary=phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.73 s, sys: 15.6 ms, total: 6.75 s\n",
      "Wall time: 6.98 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Calculate training phrase frequencies\n",
    "trainPhrases = pf.fit_transform(dfTrain.review_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "tags": [
     "hide_cell"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.52 s, sys: 0 ns, total: 2.52 s\n",
      "Wall time: 2.65 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Calculate testing phrase frequences; Note: Transform ONLY,\n",
    "# no additional fitting\n",
    "testPhrases = pf.transform(dfTest.review_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "tags": [
     "hide_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Create Latent Semantic Analysis instance\n",
    "lsaPhrases = TruncatedSVD(n_components=180, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.03 s, sys: 46.9 ms, total: 1.08 s\n",
      "Wall time: 320 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Perform Latent Semantic Analysis on training phrases\n",
    "decomp_LSAPhrases = lsaPhrases.fit(trainPhrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the raw training phrase counts into the\n",
    "# LSA decomposed features\n",
    "trainPhrasesLSA = decomp_LSAPhrases.transform(trainPhrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "tags": [
     "hide_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Transform the raw testing term counts into the\n",
    "# LSA decomposed features\n",
    "testPhrasesLSA = decomp_LSAPhrases.transform(testPhrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "tags": [
     "hide_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Create logistic regression model from phrase LSA\n",
    "model_Phrase_LSA_LR = LogisticRegression(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 31.2 ms, sys: 15.6 ms, total: 46.9 ms\n",
      "Wall time: 40.5 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Train logistic regression model on phrase LSA features\n",
    "model_Phrase_LSA_LR = model_LSA_LR.fit(trainPhrasesLSA, dfTrain.failed_hygiene)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 03 Logistic Regression of LSA from Phrase Frequencies\n",
      "-----\n",
      "F-1 score: 0.647059\n",
      "True Negatives: 49\n",
      "True Positives: 55\n",
      "False Negatives: 31\n",
      "False Positives: 29\n"
     ]
    }
   ],
   "source": [
    "# Calucalate F1 score\n",
    "model_Phrase_LSA_LR_Pred = model_Phrase_LSA_LR.predict(testPhrasesLSA)\n",
    "printModelF1(dfTest.failed_hygiene, model_Phrase_LSA_LR_Pred, \\\n",
    "             \"Model 04 Logistic Regression of LSA from Phrase Frequencies\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 05: K-Nearest Neighbor Classifier of Unigrams\n",
    "\n",
    "*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "tags": [
     "hide_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Create KNN classifier\n",
    "model_KNN = KNeighborsClassifier(n_neighbors=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15.6 ms, sys: 15.6 ms, total: 31.2 ms\n",
      "Wall time: 1.39 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Train KNN classifier on training terms\n",
    "model_KNN = model_KNN.fit(trainTerms, dfTrain.failed_hygiene)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 04 K-Nearest Neighbor Classifier for Term Frequencies\n",
      "-----\n",
      "F-1 score: 0.551282\n",
      "True Negatives: 51\n",
      "True Positives: 43\n",
      "False Negatives: 43\n",
      "False Positives: 27\n"
     ]
    }
   ],
   "source": [
    "# Calucalate F1 score\n",
    "model_KNN_Pred = model_KNN.predict(testTerms)\n",
    "printModelF1(dfTest.failed_hygiene, model_KNN_Pred, \\\n",
    "             \"Model 05 K-Nearest Neighbor Classifier for Term Frequencies\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 06: K-Nearest Neighbor Classifier of Unigrams\n",
    "\n",
    "*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "tags": [
     "hide_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Create Random Forest classifier\n",
    "model_RF = RandomForestClassifier(n_estimators=55, criterion=\"entropy\", random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 203 ms, sys: 0 ns, total: 203 ms\n",
      "Wall time: 202 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Train Random Forest classifier on training terms\n",
    "model_RF = model_RF.fit(trainTerms, dfTrain.failed_hygiene)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 06 Random Forest Classifer for Term Frequencies\n",
      "-----\n",
      "F-1 score: 0.627219\n",
      "True Negatives: 48\n",
      "True Positives: 53\n",
      "False Negatives: 33\n",
      "False Positives: 30\n"
     ]
    }
   ],
   "source": [
    "# Calucalate F1 score\n",
    "model_RF_Pred = model_RF.predict(testTerms)\n",
    "printModelF1(dfTest.failed_hygiene, model_RF_Pred, \\\n",
    "             \"Model 06 Random Forest Classifer for Term Frequencies\")"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
