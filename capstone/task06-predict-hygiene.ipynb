{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loganjtravis@gmail.com (Logan Travis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "tags": [
     "hide_cell"
    ]
   },
   "outputs": [],
   "source": [
    "%%capture --no-stdout\n",
    "\n",
    "# Imports; captures errors to supress warnings about changing\n",
    "# import syntax\n",
    "from itertools import compress\n",
    "import matplotlib.pyplot as plot\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "hide_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Set random seed for repeatability\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": [
     "hide_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Set matplotlib to inline to preserve images in PDF\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "From course page [Week 5 > Task 6 Information > Task 6 Overview](https://www.coursera.org/learn/data-mining-project/supplement/gvCsC/task-4-and-5-overview):\n",
    "\n",
    "> In this task, you are going to predict whether a set of restaurants will pass the public health inspection tests given the corresponding Yelp text reviews along with some additional information such as the locations and cuisines offered in these restaurants. Making a prediction about an unobserved attribute using data mining techniques represents a wide range of important applications of data mining. Through working on this task, you will gain direct experience with such an application. Due to the flexibility of using as many indicators for prediction as possible, this would also give you an opportunity to potentially combine many different algorithms you have learned from the courses in the Data Mining Specialization to solve a real world problem and experiment with different methods to understand whatâ€™s the most effective way of solving the problem.\n",
    "> \n",
    "> **About the Dataset**\n",
    "You should first [download the dataset](https://d396qusza40orc.cloudfront.net/dataminingcapstone/Task6/Hygiene.tar.gz). The dataset is composed of a training subset containing 546 restaurants used for training your classifier, in addition to a testing subset of 12753 restaurants used for evaluating the performance of the classifier. In the training subset, you will be provided with a binary label for each restaurant, which indicates whether the restaurant has passed the latest public health inspection test or not, whereas for the testing subset, you will not have access to any labels. The dataset is spread across three files such that the first 546 lines in each file correspond to the training subset, and the rest are part of the testing subset. Below is a description of each file:\n",
    ">\n",
    "> * hygiene.dat: Each line contains the concatenated text reviews of one restaurant.\n",
    "> * hygiene.dat.labels: For the first 546 lines, a binary label (0 or 1) is used where a 0 indicates that the restaurant has passed the latest public health inspection test, while a 1 means that the restaurant has failed the test. The rest of the lines have \"[None]\" in their label field implying that they are part of the testing subset.\n",
    "> * hygiene.dat.additional: It is a CSV (Comma-Separated Values) file where the first value is a list containing the cuisines offered, the second value is the zip code, which gives an idea about the location, the third is the number of reviews, and the fourth is the average rating, which can vary between 0 and 5 (5 being the best)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Note on This Report\n",
    "\n",
    "I hid much of my code displaying only chunks that clarified my process. My previous reports exceeded 15 pages, mostly Python code. Reviewers suggested replacing code with written descriptions for clarity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictive Model 01: Unigrams and Logistic Regression\n",
    "\n",
    "I start by representing text as a unigram vector then applying logistic regression. This predictive model gives a useful baseline for future methods. It also highlights the difficulty of the prediction: Logistic regression alone proves an *incredibly* poor predictor!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": [
     "hide_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Set paths to data source, work in process (\"WIP\"), and output\n",
    "PATH_SOURCE = \"source\"\n",
    "PATH_WIP = \"wip\"\n",
    "PATH_OUTPUT = \"output\"\n",
    "\n",
    "# Set file paths\n",
    "PATH_SOURCE_TRAIN_TEXT = f\"{PATH_SOURCE}/Hygiene/train_hygiene.dat\"\n",
    "PATH_SOURCE_TRAIN_LABELS = f\"{PATH_SOURCE}/Hygiene/train_hygiene.dat.labels\"\n",
    "PATH_SOURCE_TRAIN_REST = f\"{PATH_SOURCE}/Hygiene/train_hygiene.dat.additional\"\n",
    "PATH_SOURCE_TARGET_TEXT = f\"{PATH_SOURCE}/Hygiene/target_hygiene.dat\"\n",
    "PATH_SOURCE_TARGET_REST = f\"{PATH_SOURCE}/Hygiene/target_hygiene.dat.additional\"\n",
    "\n",
    "# Set output paths\n",
    "PATH_OUTPUT_PRED_LABELS = f\"{PATH_OUTPUT}/pred_hygiene.dat.labels\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get training text and labels\n",
    "with open(PATH_SOURCE_TRAIN_TEXT) as f:\n",
    "    arrTrainText = [l.rstrip() for l in f]\n",
    "with open(PATH_SOURCE_TRAIN_LABELS) as f:\n",
    "    arrTrainLabels = [l.rstrip() == \"1\" for l in f]\n",
    "dfTrain = pd.DataFrame(data={\"failed_hygiene\": arrTrainLabels, \"review_text\": arrTrainText})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing sets\n",
    "dfTrain[\"use\"] = \"train\"\n",
    "dfTrain.at[random.sample(range(dfTrain.shape[0]), int(dfTrain.shape[0]*0.3)), \"use\"] = \"test\"\n",
    "dfTrain.use = dfTrain.use.astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>failed_hygiene</th>\n",
       "      <th>review_text</th>\n",
       "      <th>use</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>The baguettes and rolls are excellent, and alt...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>I live up the street from Betty. &amp;#160;When my...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>I'm worried about how I will review this place...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>Why can't you access them on Google street vie...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>Things to like about this place: homemade guac...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>True</td>\n",
       "      <td>I had been holding off on visiting Bastille fo...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>True</td>\n",
       "      <td>I had gone by this place as they were moving i...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>False</td>\n",
       "      <td>Any chance I get to eat with my hands and have...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>False</td>\n",
       "      <td>My favorite Thai restaurant in the U-District....</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>False</td>\n",
       "      <td>I'm pretty sure someone who was born and raise...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   failed_hygiene                                        review_text    use\n",
       "0            True  The baguettes and rolls are excellent, and alt...  train\n",
       "1            True  I live up the street from Betty. &#160;When my...  train\n",
       "2            True  I'm worried about how I will review this place...  train\n",
       "3           False  Why can't you access them on Google street vie...  train\n",
       "4           False  Things to like about this place: homemade guac...  train\n",
       "5            True  I had been holding off on visiting Bastille fo...   test\n",
       "6            True  I had gone by this place as they were moving i...   test\n",
       "7           False  Any chance I get to eat with my hands and have...   test\n",
       "8           False  My favorite Thai restaurant in the U-District....   test\n",
       "9           False  I'm pretty sure someone who was born and raise...  train"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect first 10 rows\n",
    "dfTrain.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>review_text</th>\n",
       "      <th colspan=\"2\" halign=\"left\">review_text_len</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>use</th>\n",
       "      <th>failed_hygiene</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">test</th>\n",
       "      <th>False</th>\n",
       "      <td>86</td>\n",
       "      <td>6329.860465</td>\n",
       "      <td>10091.451518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>77</td>\n",
       "      <td>10411.194805</td>\n",
       "      <td>13845.613250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">train</th>\n",
       "      <th>False</th>\n",
       "      <td>187</td>\n",
       "      <td>7274.946524</td>\n",
       "      <td>9696.181689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>196</td>\n",
       "      <td>9479.117347</td>\n",
       "      <td>11288.419323</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     review_text review_text_len              \n",
       "                           count            mean           std\n",
       "use   failed_hygiene                                          \n",
       "test  False                   86     6329.860465  10091.451518\n",
       "      True                    77    10411.194805  13845.613250\n",
       "train False                  187     7274.946524   9696.181689\n",
       "      True                   196     9479.117347  11288.419323"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sanity check on training versus testing split\n",
    "dfTrain[\"review_text_len\"] = dfTrain.review_text.str.len()\n",
    "dfTrain.groupby([\"use\", \"failed_hygiene\"]).agg({\n",
    "    \"review_text\": [\"count\"],\n",
    "    \"review_text_len\": [\"mean\", \"std\"]\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Unigram Frequency Matrix\n",
    "\n",
    "I chose not to use IDF weighting because the data concatenated all reviews for a single restaurant with no delimiter to split them. Instead I count terms then normalize appearances for each restaurant.\n",
    "\n",
    "One caution: The training data does not include all possible terms. The testing data will likely include new terms as will future reviews. I intend this first model as a simple baseline so do not address the problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set token limit\n",
    "MAX_FEATURES = 100000\n",
    "\n",
    "# Set document frequency ceiling\n",
    "MAX_DF = 1.0\n",
    "\n",
    "# Set document frequency floor\n",
    "MIN_DF = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyTokenizer:\n",
    "    def __init__(self):\n",
    "        \"\"\"String tokenizer utilizing lemmatizing and stemming.\"\"\"\n",
    "        self.wnl = nltk.stem.WordNetLemmatizer()\n",
    "    \n",
    "    def __call__(self, document):\n",
    "        \"\"\"Return tokens from a string.\"\"\"\n",
    "        return [self.wnl.lemmatize(token) for \\\n",
    "                        token in nltk.word_tokenize(document)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create TF vectorizer \n",
    "tf = CountVectorizer(max_features=MAX_FEATURES, max_df=MAX_DF, \\\n",
    "                     min_df=MIN_DF, stop_words=\"english\", \\\n",
    "                     tokenizer=MyTokenizer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.08 s, sys: 0 ns, total: 6.08 s\n",
      "Wall time: 6.11 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Calculate training term frequencies\n",
    "trainTerms = tf.fit_transform(dfTrain[dfTrain.use == \"train\"].review_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize for each restaurant\n",
    "trainTerms = trainTerms / trainTerms.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.58 s, sys: 0 ns, total: 2.58 s\n",
      "Wall time: 2.63 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Calculate testing term frequences; Note: Transform ONLY,\n",
    "# no additional fitting\n",
    "testTerms = tf.transform(dfTrain[dfTrain.use == \"test\"].review_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize for each restaurant\n",
    "testTerms = testTerms / testTerms.sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create logistic regression model\n",
    "model_TF_LR = LogisticRegression(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 62.5 ms, sys: 0 ns, total: 62.5 ms\n",
      "Wall time: 31.6 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Train logistic regression model\n",
    "model_TF_LR = model_TF_LR.fit(trainTerms, dfTrain[dfTrain.use == \"train\"].failed_hygiene)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 01 Logistic Regression of Term Probabilities F-1 Score: 0.647059\n"
     ]
    }
   ],
   "source": [
    "# Calucalate F1 score\n",
    "model_TF_LR_TestPred = model_TF_LR.predict(testTerms)\n",
    "model_TF_LR_TestF1 = f1_score(dfTrain[dfTrain.use == \"test\"].failed_hygiene, model_TF_LR_TestPred)\n",
    "print(\"Model 01 Logistic Regression of Term Probabilities F-1 Score: {:.6f}\".format(model_TF_LR_TestF1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negatives: 2\n",
      "True Positives: 77\n",
      "False Positives: 84\n",
      "False Negatives: 0\n"
     ]
    }
   ],
   "source": [
    "# Display confusion matrix\n",
    "model_TF_LR_CM = confusion_matrix(dfTrain[dfTrain.use == \"test\"].failed_hygiene, testPred)\n",
    "print(\"True Negatives: {0:,}\\nTrue Positives: {3:,}\\nFalse Positives: {1:,}\\nFalse Negatives: {2:,}\".format(*model_TF_LR_CM.ravel()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfe = RFE(model_TF_LR, n_features_to_select=10, step=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 28.9 s, sys: 14 s, total: 42.9 s\n",
      "Wall time: 27 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Reduce features using Recursive Feature Elimination\n",
    "rfe = rfe.fit(trainTerms, dfTrain[dfTrain.use == \"train\"].failed_hygiene)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['#', '&', '.', '...', '160', ';', '?', 'best', 'thai', 'wa']"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(compress(tf.get_feature_names(), rfe.support_))"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
