{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loganjtravis@gmail.com (Logan Travis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "hide_cell"
    ]
   },
   "outputs": [],
   "source": [
    "%%capture --no-stdout\n",
    "\n",
    "# Imports; captures errors to supress warnings about changing\n",
    "# import syntax\n",
    "from itertools import compress\n",
    "import matplotlib.pyplot as plot\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "hide_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Set random seed for repeatability\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "hide_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Set matplotlib to inline to preserve images in PDF\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "From course page [Week 5 > Task 6 Information > Task 6 Overview](https://www.coursera.org/learn/data-mining-project/supplement/gvCsC/task-4-and-5-overview):\n",
    "\n",
    "> In this task, you are going to predict whether a set of restaurants will pass the public health inspection tests given the corresponding Yelp text reviews along with some additional information such as the locations and cuisines offered in these restaurants. Making a prediction about an unobserved attribute using data mining techniques represents a wide range of important applications of data mining. Through working on this task, you will gain direct experience with such an application. Due to the flexibility of using as many indicators for prediction as possible, this would also give you an opportunity to potentially combine many different algorithms you have learned from the courses in the Data Mining Specialization to solve a real world problem and experiment with different methods to understand whatâ€™s the most effective way of solving the problem.\n",
    "> \n",
    "> **About the Dataset**\n",
    "You should first [download the dataset](https://d396qusza40orc.cloudfront.net/dataminingcapstone/Task6/Hygiene.tar.gz). The dataset is composed of a training subset containing 546 restaurants used for training your classifier, in addition to a testing subset of 12753 restaurants used for evaluating the performance of the classifier. In the training subset, you will be provided with a binary label for each restaurant, which indicates whether the restaurant has passed the latest public health inspection test or not, whereas for the testing subset, you will not have access to any labels. The dataset is spread across three files such that the first 546 lines in each file correspond to the training subset, and the rest are part of the testing subset. Below is a description of each file:\n",
    ">\n",
    "> * hygiene.dat: Each line contains the concatenated text reviews of one restaurant.\n",
    "> * hygiene.dat.labels: For the first 546 lines, a binary label (0 or 1) is used where a 0 indicates that the restaurant has passed the latest public health inspection test, while a 1 means that the restaurant has failed the test. The rest of the lines have \"[None]\" in their label field implying that they are part of the testing subset.\n",
    "> * hygiene.dat.additional: It is a CSV (Comma-Separated Values) file where the first value is a list containing the cuisines offered, the second value is the zip code, which gives an idea about the location, the third is the number of reviews, and the fourth is the average rating, which can vary between 0 and 5 (5 being the best)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Note on This Report\n",
    "\n",
    "I hid much of my code displaying only chunks that clarified my process. My previous reports exceeded 15 pages, mostly Python code. Reviewers suggested replacing code with written descriptions for clarity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictive Model 01: Unigrams and Logistic Regression\n",
    "\n",
    "I start by representing text as a unigram vector then applying logistic regression. This predictive model gives a useful baseline for future methods. It also highlights the difficulty of the prediction: Logistic regression alone proves an *incredibly* poor predictor!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "hide_cell"
    ]
   },
   "source": [
    "## Prepare Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": [
     "hide_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Set paths to data source, work in process (\"WIP\"), and output\n",
    "PATH_SOURCE = \"source\"\n",
    "PATH_WIP = \"wip\"\n",
    "PATH_OUTPUT = \"output\"\n",
    "\n",
    "# Set file paths\n",
    "PATH_SOURCE_TRAIN_TEXT = f\"{PATH_SOURCE}/Hygiene/train_hygiene.dat\"\n",
    "PATH_SOURCE_TRAIN_LABELS = f\"{PATH_SOURCE}/Hygiene/train_hygiene.dat.labels\"\n",
    "PATH_SOURCE_TRAIN_REST = f\"{PATH_SOURCE}/Hygiene/train_hygiene.dat.additional\"\n",
    "PATH_SOURCE_TARGET_TEXT = f\"{PATH_SOURCE}/Hygiene/target_hygiene.dat\"\n",
    "PATH_SOURCE_TARGET_REST = f\"{PATH_SOURCE}/Hygiene/target_hygiene.dat.additional\"\n",
    "\n",
    "# Set output paths\n",
    "PATH_OUTPUT_PRED_LABELS = f\"{PATH_OUTPUT}/pred_hygiene.dat.labels\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": [
     "hide_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Get training text and labels\n",
    "with open(PATH_SOURCE_TRAIN_TEXT) as f:\n",
    "    arrTrainText = [l.rstrip() for l in f]\n",
    "with open(PATH_SOURCE_TRAIN_LABELS) as f:\n",
    "    arrTrainLabels = [l.rstrip() == \"1\" for l in f]\n",
    "dfTrain = pd.DataFrame(data={\"failed_hygiene\": arrTrainLabels, \"review_text\": arrTrainText})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": [
     "hide_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Split data into training and testing sets\n",
    "dfTrain[\"review_text_len\"] = dfTrain.review_text.str.len()\n",
    "dfTrain, dfTest = train_test_split(dfTrain, test_size=0.3, random_state=84)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": [
     "hide_cell"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>failed_hygiene</th>\n",
       "      <th>review_text</th>\n",
       "      <th>review_text_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>463</th>\n",
       "      <td>True</td>\n",
       "      <td>Lovely place! Great neighborhood feel, excelle...</td>\n",
       "      <td>17352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>False</td>\n",
       "      <td>The Crab Spring rolls were absolutely amazing!...</td>\n",
       "      <td>12390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>False</td>\n",
       "      <td>We went about a year ago... the experience was...</td>\n",
       "      <td>3107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>False</td>\n",
       "      <td>I was expecting a lot more given all the great...</td>\n",
       "      <td>2566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>False</td>\n",
       "      <td>This joint became a regular stop for us when w...</td>\n",
       "      <td>4765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545</th>\n",
       "      <td>False</td>\n",
       "      <td>A for effort. If you happen to be stuck with s...</td>\n",
       "      <td>18692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>True</td>\n",
       "      <td>Eat breakfast here.This restaurant has one of ...</td>\n",
       "      <td>4837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>False</td>\n",
       "      <td>I was going to watch a movie at SIFF but wante...</td>\n",
       "      <td>9730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>True</td>\n",
       "      <td>All I had here were cha sao bao (BBQ pork buns...</td>\n",
       "      <td>4814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>False</td>\n",
       "      <td>One of the best Phillies in the city. Service ...</td>\n",
       "      <td>326</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     failed_hygiene                                        review_text  \\\n",
       "463            True  Lovely place! Great neighborhood feel, excelle...   \n",
       "240           False  The Crab Spring rolls were absolutely amazing!...   \n",
       "461           False  We went about a year ago... the experience was...   \n",
       "257           False  I was expecting a lot more given all the great...   \n",
       "407           False  This joint became a regular stop for us when w...   \n",
       "545           False  A for effort. If you happen to be stuck with s...   \n",
       "465            True  Eat breakfast here.This restaurant has one of ...   \n",
       "331           False  I was going to watch a movie at SIFF but wante...   \n",
       "381            True  All I had here were cha sao bao (BBQ pork buns...   \n",
       "66            False  One of the best Phillies in the city. Service ...   \n",
       "\n",
       "     review_text_len  \n",
       "463            17352  \n",
       "240            12390  \n",
       "461             3107  \n",
       "257             2566  \n",
       "407             4765  \n",
       "545            18692  \n",
       "465             4837  \n",
       "331             9730  \n",
       "381             4814  \n",
       "66               326  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect first 10 rows\n",
    "dfTrain.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": [
     "hide_cell"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>review_text</th>\n",
       "      <th colspan=\"2\" halign=\"left\">review_text_len</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>failed_hygiene</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>195</td>\n",
       "      <td>7276.015385</td>\n",
       "      <td>10327.798184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>187</td>\n",
       "      <td>9967.219251</td>\n",
       "      <td>12589.871449</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               review_text review_text_len              \n",
       "                     count            mean           std\n",
       "failed_hygiene                                          \n",
       "False                  195     7276.015385  10327.798184\n",
       "True                   187     9967.219251  12589.871449"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sanity check on training versus testing split\n",
    "dfTrain.groupby([\"failed_hygiene\"]).agg({\n",
    "    \"review_text\": [\"count\"],\n",
    "    \"review_text_len\": [\"mean\", \"std\"]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": [
     "hide_cell"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>review_text</th>\n",
       "      <th colspan=\"2\" halign=\"left\">review_text_len</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>failed_hygiene</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>78</td>\n",
       "      <td>6230.256410</td>\n",
       "      <td>8406.959927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>86</td>\n",
       "      <td>9252.313953</td>\n",
       "      <td>10821.455737</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               review_text review_text_len              \n",
       "                     count            mean           std\n",
       "failed_hygiene                                          \n",
       "False                   78     6230.256410   8406.959927\n",
       "True                    86     9252.313953  10821.455737"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sanity check on training versus testing split\n",
    "dfTest.groupby([\"failed_hygiene\"]).agg({\n",
    "    \"review_text\": [\"count\"],\n",
    "    \"review_text_len\": [\"mean\", \"std\"]\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Unigram Probability Matrix\n",
    "\n",
    "I chose not to use IDF weighting because the data concatenated all reviews for a single restaurant with no delimiter to split them. Instead I count terms then normalize appearances for each restaurant creating a term probability matrix. A couple upfront comments:\n",
    "\n",
    "* Logistic regression works best when the number of samples far exceeds the number of variables. That is not the case for this data set. I expect very poor performance with high sensitivity to model parameters.\n",
    "* I did not tune the term vectorizer; it includes all terms found in the training data.\n",
    "* I will tune the parameters in the next model. I intend this model as a *naive* baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": [
     "hide_cell"
    ]
   },
   "outputs": [],
   "source": [
    "class MyTokenizer:\n",
    "    def __init__(self):\n",
    "        \"\"\"String tokenizer utilizing lemmatizing and stemming.\"\"\"\n",
    "        self.wnl = nltk.stem.WordNetLemmatizer()\n",
    "    \n",
    "    def __call__(self, document):\n",
    "        \"\"\"Return tokens from a string.\"\"\"\n",
    "        return [self.wnl.lemmatize(token) for \\\n",
    "                        token in nltk.word_tokenize(document)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": [
     "hide_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Set token limit\n",
    "MAX_FEATURES = 100000\n",
    "\n",
    "# Set document frequency ceiling\n",
    "MAX_DF = 1.0\n",
    "\n",
    "# Set document frequency floor\n",
    "MIN_DF = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": [
     "hide_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Create TF vectorizer \n",
    "tf = CountVectorizer(max_features=MAX_FEATURES, max_df=MAX_DF, \\\n",
    "                     min_df=MIN_DF, stop_words=\"english\", \\\n",
    "                     tokenizer=MyTokenizer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.09 s, sys: 609 ms, total: 7.7 s\n",
      "Wall time: 7.77 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Calculate training term frequencies\n",
    "trainTerms = tf.fit_transform(dfTrain.review_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "382 restaurant reviews extracted into 23,107 unigram terms.\n"
     ]
    }
   ],
   "source": [
    "# Normalize for each restaurant\n",
    "trainTerms = trainTerms / trainTerms.sum(axis=1)\n",
    "print(\"{:,} restaurant reviews extracted into {:,} unigram terms.\".format(*trainTerms.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": [
     "hide_cell"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.39 s, sys: 0 ns, total: 2.39 s\n",
      "Wall time: 2.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Calculate testing term frequences; Note: Transform ONLY,\n",
    "# no additional fitting\n",
    "testTerms = tf.transform(dfTest.review_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": [
     "hide_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Normalize for each restaurant\n",
    "testTerms = testTerms / testTerms.sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": [
     "hide_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Create logistic regression model\n",
    "model_TF_LR = LogisticRegression(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15.6 ms, sys: 0 ns, total: 15.6 ms\n",
      "Wall time: 24.3 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Train logistic regression model\n",
    "model_TF_LR = model_TF_LR.fit(trainTerms, dfTrain.failed_hygiene)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 01 Logistic Regression of Term Probabilities F-1 Score: 0.000000\n"
     ]
    }
   ],
   "source": [
    "# Calucalate F1 score\n",
    "model_TF_LR_Pred = model_TF_LR.predict(testTerms)\n",
    "model_TF_LR_F1 = f1_score(dfTest.failed_hygiene, model_TF_LR_Pred)\n",
    "print(\"Model 01 Logistic Regression of Term Probabilities F-1 Score: {:.6f}\".format(model_TF_LR_F1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negatives: 77\n",
      "True Positives: 0\n",
      "False Negatives: 86\n",
      "False Positives: 1\n"
     ]
    }
   ],
   "source": [
    "# Display confusion matrix\n",
    "model_TF_LR_CM = confusion_matrix(dfTest.failed_hygiene, model_TF_LR_Pred)\n",
    "print(\"True Negatives: {0:,}\\nTrue Positives: {3:,}\\nFalse Negatives: {2:,}\\nFalse Positives: {1:,}\".format(*model_TF_LR_CM.ravel()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The simple logistic regression performed *horribly*. It only predict **one** failed hygiene inspection in the test data and that was a false positive. Review text simply includes too much noise. While we would anticipate hygiene issues to appear in reviews, we should also expect them to drown in a sea of non-hygiene related reviews about the food, service, location, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictive Model 02: Remove Noise from Unigrams and Logistic Regression\n",
    "\n",
    "I next try a feature selection method called Recursive Feature Elimination. The 22,000+ terms found in the training data far exceed the training sample (382). If a simple logistic regession has predictive value, it first needs to train on only the most useful features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find Most Predictive Terms using Recursive Feature Elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": [
     "hide_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Create logistic regression model for RFE\n",
    "model_TF_LR_RFE = LogisticRegression(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": [
     "hide_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Create Recursive Feature Elimination instance\n",
    "rfe_TF_LR_RFE = RFE(model_TF_LR_RFE, n_features_to_select=100, step=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 12s, sys: 16.6 s, total: 1min 28s\n",
      "Wall time: 27 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Reduce features using Recursive Feature Elimination\n",
    "rfe_TF_LR_RFE = rfe_TF_LR_RFE.fit(trainTerms, dfTrain.failed_hygiene)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": [
     "hide_cell"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['!',\n",
       " '#',\n",
       " '$',\n",
       " '&',\n",
       " \"'ll\",\n",
       " \"'s\",\n",
       " \"'ve\",\n",
       " ',',\n",
       " '.',\n",
       " '...',\n",
       " '160',\n",
       " ':',\n",
       " ';',\n",
       " '?',\n",
       " '``',\n",
       " 'amp',\n",
       " 'around..',\n",
       " 'atmosphere',\n",
       " 'awesome',\n",
       " 'bad',\n",
       " 'banh',\n",
       " 'bar',\n",
       " 'beer',\n",
       " 'best',\n",
       " 'burger',\n",
       " 'cash',\n",
       " 'cheap',\n",
       " 'cheese',\n",
       " 'chicken',\n",
       " 'chinese',\n",
       " 'city',\n",
       " 'curry',\n",
       " 'decor',\n",
       " 'dim',\n",
       " 'dish',\n",
       " 'drink',\n",
       " 'egg',\n",
       " 'falafel',\n",
       " 'far',\n",
       " 'fast',\n",
       " 'food',\n",
       " 'fried',\n",
       " 'friendly',\n",
       " 'fry',\n",
       " 'good',\n",
       " 'grab',\n",
       " 'great',\n",
       " 'happy',\n",
       " 'hot',\n",
       " 'just',\n",
       " 'know',\n",
       " 'like',\n",
       " 'love',\n",
       " 'meal',\n",
       " 'meat',\n",
       " 'mi',\n",
       " 'minute',\n",
       " 'monday',\n",
       " 'morning',\n",
       " \"n't\",\n",
       " 'nice',\n",
       " 'noodle',\n",
       " 'order',\n",
       " 'oyster',\n",
       " 'pad',\n",
       " 'parking',\n",
       " 'philly',\n",
       " 'pho',\n",
       " 'pizza',\n",
       " 'place',\n",
       " 'pork',\n",
       " 'pretty',\n",
       " 'price',\n",
       " 'quick',\n",
       " 'really',\n",
       " 'respectable',\n",
       " 'rice',\n",
       " 'roll',\n",
       " 'room',\n",
       " 'salad',\n",
       " 'say',\n",
       " 'selection',\n",
       " 'spaghetti',\n",
       " 'special',\n",
       " 'special..',\n",
       " 'spicy',\n",
       " 'staff',\n",
       " 'star',\n",
       " 'sum',\n",
       " 'super',\n",
       " 'thai',\n",
       " 'think',\n",
       " 'time',\n",
       " 'tofu',\n",
       " 'town',\n",
       " 'tried',\n",
       " 'try',\n",
       " 'unless',\n",
       " 'wa',\n",
       " 'went']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect remaing terms\n",
    "list(compress(tf.get_feature_names(), rfe_TF_LR_RFE.get_support()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restrict term probability matrices to best terms from RFE\n",
    "trainTerms_RFE = trainTerms[:, rfe_TF_LR_RFE.get_support(indices=True)]\n",
    "testTerms_RFE = testTerms[:, rfe_TF_LR_RFE.get_support(indices=True)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Logistic Regression Model after RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 2.55 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Train logistic regression model\n",
    "model_TF_LR_RFE = model_TF_LR_RFE.fit(trainTerms_RFE, dfTrain.failed_hygiene)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 02 Logistic Regression of Term Probabilities after RFE F-1 Score: 0.000000\n"
     ]
    }
   ],
   "source": [
    "# Calucalate F1 score\n",
    "model_TF_LR_RFE_Pred = model_TF_LR_RFE.predict(testTerms_RFE)\n",
    "model_TF_LR_RFE_F1 = f1_score(dfTest.failed_hygiene, model_TF_LR_RFE_Pred)\n",
    "print(\"Model 02 Logistic Regression of Term Probabilities after RFE F-1 Score: {:.6f}\".format(model_TF_LR_RFE_F1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negatives: 77\n",
      "True Positives: 0\n",
      "False Negatives: 86\n",
      "False Positives: 1\n"
     ]
    }
   ],
   "source": [
    "# Display confusion matrix\n",
    "model_TF_LR_RFE_CM = confusion_matrix(dfTest.failed_hygiene, model_TF_LR_RFE_Pred)\n",
    "print(\"True Negatives: {0:,}\\nTrue Positives: {3:,}\\nFalse Negatives: {2:,}\\nFalse Positives: {1:,}\".format(*model_TF_LR_RFE_CM.ravel()))"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
